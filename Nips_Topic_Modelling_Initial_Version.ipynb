{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nips_Topic_Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTGsUVRvo9MK1g6v1Xy+0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meiruv/NIPS-Papers-Analysis/blob/main/Nips_Topic_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqldDG4ENZKw"
      },
      "source": [
        "Taking a go on this dataset:\n",
        "https://www.kaggle.com/rowhitswami/nips-papers-1987-2019-updated/tasks?taskId=2960\n",
        "\n",
        "The task here is to model the topic of each NIPS paper using LDA and evaluate the results independently. I will try modelling with LDA and with BERT as proposed here: https://github.com/MaartenGr/BERTopic\n",
        "\n",
        "I will need to check if I the abstracts are enough for the modelling or if the full text should be used.\n",
        "I will want to check if the author's name can somehow be used for validation (if I know an author is an expert of one field and the paper is classified under another topic I might suspect the classification is wrong)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NctZ6uTFroZL"
      },
      "source": [
        "# ! python -m spacy download en_core_web_lg\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni59vw6pO6C9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO-WM0hbNRdv"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Ttk_-DOdqy"
      },
      "source": [
        "# Fetching the Data From Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZuKGGRYOglU",
        "outputId": "519d2f89-717a-4125-e30b-d7f0f2605c1a"
      },
      "source": [
        "! pip install -q kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjPKoI2NOg_s",
        "outputId": "044817c1-a91f-401f-88bb-af2380e7875e"
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/\n",
        "! kaggle datasets download -d rowhitswami/nips-papers-1987-2019-updated"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading nips-papers-1987-2019-updated.zip to /content\n",
            " 93% 99.0M/106M [00:00<00:00, 105MB/s] \n",
            "100% 106M/106M [00:00<00:00, 115MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3n7_KUfOqEl"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'nips-papers-1987-2019-updated.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('nips_papers')\n",
        "zip_ref.close()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_6zflumP2-8",
        "outputId": "8282a434-9922-4639-e943-ba20f1392d6a"
      },
      "source": [
        "!ls nips_papers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "authors.csv  papers.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPnb3fkRP6Xi"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx8TvNS9P9Zv"
      },
      "source": [
        "# Exploratory Analysis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkIUIc5wQAse"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgvmGOE9igi4"
      },
      "source": [
        "## Authors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "86ybeqzlQrB0",
        "outputId": "bd37aedf-7073-4331-d877-d00fa7803007"
      },
      "source": [
        "authors_df = pd.read_csv('nips_papers/authors.csv')\n",
        "print('Authors df Shape : ',authors_df.shape)\n",
        "authors_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authors df Shape :  (30237, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_id</th>\n",
              "      <th>first_name</th>\n",
              "      <th>last_name</th>\n",
              "      <th>institution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>Alan</td>\n",
              "      <td>Murray</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27</td>\n",
              "      <td>Anthony</td>\n",
              "      <td>Smith</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27</td>\n",
              "      <td>Zoe</td>\n",
              "      <td>Butler</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63</td>\n",
              "      <td>Yaser</td>\n",
              "      <td>Abu-Mostafa</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>Michael</td>\n",
              "      <td>Fleisher</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   source_id first_name    last_name institution\n",
              "0         27       Alan       Murray         NaN\n",
              "1         27    Anthony        Smith         NaN\n",
              "2         27        Zoe       Butler         NaN\n",
              "3         63      Yaser  Abu-Mostafa         NaN\n",
              "4         60    Michael     Fleisher         NaN"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV9kJ1WDQz40",
        "outputId": "21ad8e08-f510-42de-b538-9cbeb1006c67"
      },
      "source": [
        "len(authors_df['institution'].unique())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2672"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UM-7a2fHRDtt",
        "outputId": "dda06ae0-a9b4-4800-b98e-0b2976f6dfab"
      },
      "source": [
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~ need to not count all writers as different publications! group by the institution and count distinct source_id  ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "insts_and_pubs = pd.DataFrame(authors_df['institution'].value_counts()).reset_index()\n",
        "insts_and_pubs.columns = ['institution', 'Publications']\n",
        "insts_and_pubs.head(60)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>institution</th>\n",
              "      <th>Publications</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stanford University</td>\n",
              "      <td>542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MIT</td>\n",
              "      <td>464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carnegie Mellon University</td>\n",
              "      <td>446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>UC Berkeley</td>\n",
              "      <td>404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Google</td>\n",
              "      <td>342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Microsoft Research</td>\n",
              "      <td>298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>DeepMind</td>\n",
              "      <td>269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Princeton University</td>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Duke University</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Columbia University</td>\n",
              "      <td>221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Tsinghua University</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>University of Oxford</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>University of Toronto</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Google Brain</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Cornell University</td>\n",
              "      <td>169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Google DeepMind</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ETH Zurich</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>University of Washington</td>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>CMU</td>\n",
              "      <td>134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>EPFL</td>\n",
              "      <td>133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>University of Michigan</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Massachusetts Institute of Technology</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>UCLA</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Harvard University</td>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>UT Austin</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Stanford</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>University of Cambridge</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Georgia Tech</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Peking University</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>University of Pennsylvania</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Google Research</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Technion</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>IBM Research</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Facebook AI Research</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Georgia Institute of Technology</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>University of Texas at Austin</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>New York University</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Microsoft</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>University of Southern California</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>UIUC</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>University of Illinois at Urbana-Champaign</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Purdue University</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>INRIA</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>University of Alberta</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>National University of Singapore</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Johns Hopkins University</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>The Chinese University of Hong Kong</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>University of Edinburgh</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>University College London</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>University of Maryland</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Seoul National University</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>University of California, Berkeley</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>University of Minnesota</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>UC San Diego</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Tencent AI Lab</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>KAIST</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>NYU</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Inria</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>UW-Madison</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Imperial College London</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   institution  Publications\n",
              "0                          Stanford University           542\n",
              "1                                          MIT           464\n",
              "2                   Carnegie Mellon University           446\n",
              "3                                  UC Berkeley           404\n",
              "4                                       Google           342\n",
              "5                           Microsoft Research           298\n",
              "6                                     DeepMind           269\n",
              "7                         Princeton University           256\n",
              "8                              Duke University           230\n",
              "9                          Columbia University           221\n",
              "10                         Tsinghua University           196\n",
              "11                        University of Oxford           185\n",
              "12                       University of Toronto           180\n",
              "13                                Google Brain           176\n",
              "14                          Cornell University           169\n",
              "15                             Google DeepMind           163\n",
              "16                                  ETH Zurich           155\n",
              "17                    University of Washington           152\n",
              "18                                         CMU           134\n",
              "19                                        EPFL           133\n",
              "20                      University of Michigan           131\n",
              "21       Massachusetts Institute of Technology           131\n",
              "22                                        UCLA           131\n",
              "23                          Harvard University           128\n",
              "24                                   UT Austin           127\n",
              "25                                    Stanford           122\n",
              "26                     University of Cambridge           122\n",
              "27                                Georgia Tech           121\n",
              "28                           Peking University           118\n",
              "29                  University of Pennsylvania           109\n",
              "30                             Google Research           106\n",
              "31                                    Technion           105\n",
              "32                                IBM Research            97\n",
              "33                        Facebook AI Research            96\n",
              "34             Georgia Institute of Technology            89\n",
              "35               University of Texas at Austin            89\n",
              "36                         New York University            87\n",
              "37                                   Microsoft            81\n",
              "38           University of Southern California            81\n",
              "39                                        UIUC            79\n",
              "40  University of Illinois at Urbana-Champaign            75\n",
              "41                           Purdue University            70\n",
              "42                                       INRIA            69\n",
              "43                       University of Alberta            68\n",
              "44            National University of Singapore            64\n",
              "45                    Johns Hopkins University            60\n",
              "46         The Chinese University of Hong Kong            59\n",
              "47                     University of Edinburgh            59\n",
              "48                   University College London            58\n",
              "49                      University of Maryland            58\n",
              "50                   Seoul National University            57\n",
              "51          University of California, Berkeley            56\n",
              "52                     University of Minnesota            56\n",
              "53                                UC San Diego            53\n",
              "54                              Tencent AI Lab            50\n",
              "55                                       KAIST            49\n",
              "56                                         NYU            46\n",
              "57                                       Inria            45\n",
              "58                                  UW-Madison            45\n",
              "59                     Imperial College London            44"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "8KXwIVu1ROOD",
        "outputId": "306910c5-5768-4aaa-a34b-73c5fa2ea15f"
      },
      "source": [
        "a4_dims = (10, 8)\n",
        "fig, ax = plt.subplots(figsize=a4_dims)\n",
        "\n",
        "sns.set(style = \"darkgrid\", font_scale=1.3)\n",
        "ax = sns.barplot(x='Publications', y=\"institution\", data=insts_and_pubs.head(20) , palette = \"GnBu_d\")\n",
        "ax.axes.set_title(\"20 Most Publishing Institutions\",fontsize=20)\n",
        "ax.set_ylabel(\"Institution\",fontsize=13)\n",
        "ax.set_xlabel(\"# Publications Since 1987)\",fontsize=15)\n",
        "#ax.set_xticklabels(top_diff_30['Country'],rotation = 45, ha=\"right\")\n",
        "\n",
        "# fig.savefig('Biggeat_Leap_Sine_2000_Horizontal.jpg')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, '# Publications Since 1987)')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkG5zQbLT6Uf"
      },
      "source": [
        "I found it interesting to look at how many papers each institution published and compare all institutions to find top publishers. This list is limited though because some institutiona and spelled differently-for example MIT appears sometimes as MIT and sometimes as Massachusetts Institute of Technology - row 23, if we combine the amounts on those rows we get more than Stanford which means MIT is the world's leading institution in terms of publications since 1987. Another example is Google having several rows - one for brain, one for deepminds, etc. If we combine those rows it will probably be ranked higher in this table.\n",
        "Also - fun fact and a bit of pride for Israelis - the Technion is 31st in this list, which reminds us yet again that while such rankings can be calculated by absolute numbers it is more accurate to normalize them based on the institution's size and perhaps bring into the equation its amounts of funding.\n",
        "\n",
        "It would be interesting to see how many institutions got into this list from each country/continent as well as how many of them are GAMFA and corporates in general. I didn't find an easy way for calculating this so I skipped this idea for the time being."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qdogNIj7TOXU",
        "outputId": "a31b4220-a241-449d-a8b8-f17adabf41c1"
      },
      "source": [
        "# Writers per Paper distribution\n",
        "\n",
        "writers_per_paper_df = pd.DataFrame(authors_df['source_id'].value_counts()).reset_index()\n",
        "writers_per_paper_df.columns = ['source_id','n_writers']\n",
        "writers_per_paper_df.head(60)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_id</th>\n",
              "      <th>n_writers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1048</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>717</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1442</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2889</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>186</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1143</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1344</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>758</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>354</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>146</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>751</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1233</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>598</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>515</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>345</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1485</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1294</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>95</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>662</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1726</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1687</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1222</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>802</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>243</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>932</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1192</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>535</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1077</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>521</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>914</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>592</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1099</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>780</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>767</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>574</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1473</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>872</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2434</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>977</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>940</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1100</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>753</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>916</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>480</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>611</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>383</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>876</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1322</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1302</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2029</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>159</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>60</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>4399</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>981</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>289</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>881</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>1109</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>1267</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>75</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>964</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    source_id  n_writers\n",
              "0        1048         31\n",
              "1         717         30\n",
              "2        1442         30\n",
              "3        2889         29\n",
              "4         186         28\n",
              "5        1143         28\n",
              "6        1344         27\n",
              "7         758         26\n",
              "8         354         26\n",
              "9         146         26\n",
              "10        751         26\n",
              "11       1233         26\n",
              "12        598         25\n",
              "13        515         25\n",
              "14        345         25\n",
              "15       1485         25\n",
              "16       1294         25\n",
              "17         95         24\n",
              "18        662         24\n",
              "19       1726         24\n",
              "20       1687         24\n",
              "21       1222         24\n",
              "22        802         23\n",
              "23        243         23\n",
              "24        932         23\n",
              "25       1192         23\n",
              "26        535         23\n",
              "27       1077         23\n",
              "28        521         23\n",
              "29        914         22\n",
              "30        592         22\n",
              "31       1099         22\n",
              "32        780         22\n",
              "33        767         22\n",
              "34        574         22\n",
              "35       1473         22\n",
              "36        872         22\n",
              "37       2434         22\n",
              "38        977         22\n",
              "39        940         21\n",
              "40       1100         21\n",
              "41        753         21\n",
              "42        916         21\n",
              "43        480         21\n",
              "44        611         21\n",
              "45        383         21\n",
              "46        876         21\n",
              "47       1322         21\n",
              "48       1302         21\n",
              "49       2029         21\n",
              "50        159         21\n",
              "51         60         21\n",
              "52       4399         21\n",
              "53        981         21\n",
              "54        289         21\n",
              "55        881         21\n",
              "56       1109         21\n",
              "57       1267         21\n",
              "58         75         21\n",
              "59        964         21"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxpSHczIX9p0",
        "outputId": "f92e69b7-75af-4c68-c0cf-ee0339f15acc"
      },
      "source": [
        "writers_per_paper_df[writers_per_paper_df['n_writers']>=10].shape[0] - 80"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "948"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUweGeszWFlW",
        "outputId": "8ff76a00-84ba-426c-b279-0a093310af28"
      },
      "source": [
        "writers_per_paper_df.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4522, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "MFpU_wwHWtgu",
        "outputId": "a4ed642e-95b2-48cf-f612-f7fa56f99c38"
      },
      "source": [
        "writers_per_paper_df['n_writers'].hist(figsize = (10,8));"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KZShj_HX0HL"
      },
      "source": [
        "There are 4522 papers in this dataset, out of which 80 had 20 authors or more. \n",
        "948 has between 10-20 authors and the rest (3494) had less than 10 authors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKp9Qox6d2AX"
      },
      "source": [
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ same distribution but per institution - avtala smuya ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhDO4ryRYZAY",
        "outputId": "49ca7146-c356-4714-cab1-d7204be7f802"
      },
      "source": [
        "4522 - 80 - 948"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3494"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFz98hDrWCB3"
      },
      "source": [
        "# Papers per author distribution\n",
        "authors_df['author'] = authors_df['first_name']+' ' + authors_df['last_name']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "l2xLE92pdYAd",
        "outputId": "5432f7bc-8a86-433a-bf85-8a704630b2f5"
      },
      "source": [
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ use groupby instead of value counts ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "apers_per_author_df = pd.DataFrame(authors_df['author'].value_counts()).reset_index()\n",
        "papers_per_author_df.columns = ['author','n_publications']\n",
        "papers_per_author_df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>n_publications</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Michael Jordan</td>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yoshua Bengio</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bernhard Schölkopf</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Geoffrey Hinton</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Francis Bach</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               author  n_publications\n",
              "0      Michael Jordan             111\n",
              "1       Yoshua Bengio              74\n",
              "2  Bernhard Schölkopf              69\n",
              "3     Geoffrey Hinton              63\n",
              "4        Francis Bach              59"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl3uiU3Ee42a"
      },
      "source": [
        "My conclusion from this is to name my child Michael Jordan\n",
        "\n",
        "```\n",
        "`# This is formatted as code`\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Tyyui5R8hTwS",
        "outputId": "0d5eec8f-c604-4aa5-d444-da566474989d"
      },
      "source": [
        "# special request from a friend\n",
        "papers_per_author_df[papers_per_author_df['author']=='Beatrice Golomb']\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>n_publications</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9648</th>\n",
              "      <td>Beatrice Golomb</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               author  n_publications\n",
              "9648  Beatrice Golomb               1"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "4xzpts5ZfydJ",
        "outputId": "441098b6-63ee-406d-9a5d-c9703a2fd9cb"
      },
      "source": [
        "# Another way to query this, I find it useful to keep such snippets\n",
        "papers_per_author_df.loc[papers_per_author_df['author'].str.startswith('Bea', na=False)]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>n_publications</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8608</th>\n",
              "      <td>Beat Buesser</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9009</th>\n",
              "      <td>Beata Jarosiewicz</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9648</th>\n",
              "      <td>Beatrice Golomb</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12811</th>\n",
              "      <td>Beat Pfister</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13963</th>\n",
              "      <td>Beat Flepp</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  author  n_publications\n",
              "8608        Beat Buesser               1\n",
              "9009   Beata Jarosiewicz               1\n",
              "9648     Beatrice Golomb               1\n",
              "12811       Beat Pfister               1\n",
              "13963         Beat Flepp               1"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMRKKdeCZB8a"
      },
      "source": [
        "\n",
        " ### Are there communities here?\n",
        "\n",
        "Draw a graph from this data. the most basic way will be to draw an edge between each authors that published together and weight the edges based on the amount of publications they have together, then run community detection algorithm and see if there are any. also see top publishers and perhaps place the authors on a map based on their institution to see where those communities occur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "O0pdaQA4mqGZ",
        "outputId": "d02fa1ba-7266-4f2a-c39b-83cbea43b790"
      },
      "source": [
        "authors_df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_id</th>\n",
              "      <th>first_name</th>\n",
              "      <th>last_name</th>\n",
              "      <th>institution</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>Alan</td>\n",
              "      <td>Murray</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alan Murray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27</td>\n",
              "      <td>Anthony</td>\n",
              "      <td>Smith</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Anthony Smith</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27</td>\n",
              "      <td>Zoe</td>\n",
              "      <td>Butler</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Zoe Butler</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63</td>\n",
              "      <td>Yaser</td>\n",
              "      <td>Abu-Mostafa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yaser Abu-Mostafa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>Michael</td>\n",
              "      <td>Fleisher</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Michael Fleisher</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   source_id first_name    last_name institution             author\n",
              "0         27       Alan       Murray         NaN        Alan Murray\n",
              "1         27    Anthony        Smith         NaN      Anthony Smith\n",
              "2         27        Zoe       Butler         NaN         Zoe Butler\n",
              "3         63      Yaser  Abu-Mostafa         NaN  Yaser Abu-Mostafa\n",
              "4         60    Michael     Fleisher         NaN   Michael Fleisher"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "pZcOHBtqm1_M",
        "outputId": "b10ddf59-d8b6-4ed0-ce33-756906358447"
      },
      "source": [
        "author_and_paper_df = authors_df[['source_id','author']]\n",
        "author_and_paper_df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_id</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>Alan Murray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27</td>\n",
              "      <td>Anthony Smith</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27</td>\n",
              "      <td>Zoe Butler</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63</td>\n",
              "      <td>Yaser Abu-Mostafa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>Michael Fleisher</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   source_id             author\n",
              "0         27        Alan Murray\n",
              "1         27      Anthony Smith\n",
              "2         27         Zoe Butler\n",
              "3         63  Yaser Abu-Mostafa\n",
              "4         60   Michael Fleisher"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "x3Oxt5eDmqIh",
        "outputId": "13f0c1da-5a40-4a91-eec0-b9fd03c7b037"
      },
      "source": [
        "co_authors_df = author_and_paper_df.merge(author_and_paper_df, how = 'outer', on = 'source_id')\n",
        "co_authors_df_clear_1 = co_authors_df[co_authors_df['author_x']!=co_authors_df['author_y']]\n",
        "co_authors_df_clear_1.head(20)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_id</th>\n",
              "      <th>author_x</th>\n",
              "      <th>author_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27</td>\n",
              "      <td>Alan Murray</td>\n",
              "      <td>Anthony Smith</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27</td>\n",
              "      <td>Alan Murray</td>\n",
              "      <td>Zoe Butler</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>Alan Murray</td>\n",
              "      <td>Huitong Qiu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>Alan Murray</td>\n",
              "      <td>Fang Han</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>27</td>\n",
              "      <td>Alan Murray</td>\n",
              "      <td>Han Liu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>27</td>\n",
              "      <td>Alan Murray</td>\n",
              "      <td>Brian Caffo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>27</td>\n",
              "      <td>Anthony Smith</td>\n",
              "      <td>Alan Murray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>27</td>\n",
              "      <td>Anthony Smith</td>\n",
              "      <td>Zoe Butler</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>27</td>\n",
              "      <td>Anthony Smith</td>\n",
              "      <td>Huitong Qiu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>27</td>\n",
              "      <td>Anthony Smith</td>\n",
              "      <td>Fang Han</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>27</td>\n",
              "      <td>Anthony Smith</td>\n",
              "      <td>Han Liu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>27</td>\n",
              "      <td>Anthony Smith</td>\n",
              "      <td>Brian Caffo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>27</td>\n",
              "      <td>Zoe Butler</td>\n",
              "      <td>Alan Murray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>27</td>\n",
              "      <td>Zoe Butler</td>\n",
              "      <td>Anthony Smith</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>27</td>\n",
              "      <td>Zoe Butler</td>\n",
              "      <td>Huitong Qiu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>27</td>\n",
              "      <td>Zoe Butler</td>\n",
              "      <td>Fang Han</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>27</td>\n",
              "      <td>Zoe Butler</td>\n",
              "      <td>Han Liu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>27</td>\n",
              "      <td>Zoe Butler</td>\n",
              "      <td>Brian Caffo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>27</td>\n",
              "      <td>Huitong Qiu</td>\n",
              "      <td>Alan Murray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>27</td>\n",
              "      <td>Huitong Qiu</td>\n",
              "      <td>Anthony Smith</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    source_id       author_x       author_y\n",
              "1          27    Alan Murray  Anthony Smith\n",
              "2          27    Alan Murray     Zoe Butler\n",
              "3          27    Alan Murray    Huitong Qiu\n",
              "4          27    Alan Murray       Fang Han\n",
              "5          27    Alan Murray        Han Liu\n",
              "6          27    Alan Murray    Brian Caffo\n",
              "7          27  Anthony Smith    Alan Murray\n",
              "9          27  Anthony Smith     Zoe Butler\n",
              "10         27  Anthony Smith    Huitong Qiu\n",
              "11         27  Anthony Smith       Fang Han\n",
              "12         27  Anthony Smith        Han Liu\n",
              "13         27  Anthony Smith    Brian Caffo\n",
              "14         27     Zoe Butler    Alan Murray\n",
              "15         27     Zoe Butler  Anthony Smith\n",
              "17         27     Zoe Butler    Huitong Qiu\n",
              "18         27     Zoe Butler       Fang Han\n",
              "19         27     Zoe Butler        Han Liu\n",
              "20         27     Zoe Butler    Brian Caffo\n",
              "21         27    Huitong Qiu    Alan Murray\n",
              "22         27    Huitong Qiu  Anthony Smith"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWFPm7VaOyRn",
        "outputId": "5497da97-5ed1-464d-ace5-be97d830222f"
      },
      "source": [
        "co_authors_df_clear_1['author_x'] = co_authors_df_clear_1['author_x'].astype(str)\n",
        "co_authors_df_clear_1['author_y'] = co_authors_df_clear_1['author_y'].astype(str)\n",
        "\n",
        "co_authors_df_clear_1['check_string'] = co_authors_df_clear_1.apply(lambda row: ''.join(sorted([row['author_x'], row['author_y']])), axis=1)\n",
        "co_authors_df_clear = co_authors_df_clear_1.drop_duplicates(subset=['check_string','source_id']).drop(columns = ['check_string','source_id'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "SEnkM1qs2Xgb",
        "outputId": "219c9a78-a3d8-4908-9d51-344a8c86a4cd"
      },
      "source": [
        "co_authors_df_clear"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author_x</th>\n",
              "      <th>author_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alan Murray</td>\n",
              "      <td>Anthony Smith</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Alan Murray</td>\n",
              "      <td>Zoe Butler</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alan Murray</td>\n",
              "      <td>Huitong Qiu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Alan Murray</td>\n",
              "      <td>Fang Han</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Alan Murray</td>\n",
              "      <td>Han Liu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297852</th>\n",
              "      <td>Manish Purohit</td>\n",
              "      <td>Erik Vee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297853</th>\n",
              "      <td>Manish Purohit</td>\n",
              "      <td>Joshua Wang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297857</th>\n",
              "      <td>Zoya Svitkina</td>\n",
              "      <td>Erik Vee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297858</th>\n",
              "      <td>Zoya Svitkina</td>\n",
              "      <td>Joshua Wang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297863</th>\n",
              "      <td>Erik Vee</td>\n",
              "      <td>Joshua Wang</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>133512 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              author_x       author_y\n",
              "1          Alan Murray  Anthony Smith\n",
              "2          Alan Murray     Zoe Butler\n",
              "3          Alan Murray    Huitong Qiu\n",
              "4          Alan Murray       Fang Han\n",
              "5          Alan Murray        Han Liu\n",
              "...                ...            ...\n",
              "297852  Manish Purohit       Erik Vee\n",
              "297853  Manish Purohit    Joshua Wang\n",
              "297857   Zoya Svitkina       Erik Vee\n",
              "297858   Zoya Svitkina    Joshua Wang\n",
              "297863        Erik Vee    Joshua Wang\n",
              "\n",
              "[133512 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxyGq21RONhp",
        "outputId": "e49203d3-8998-4531-cc7e-a5e985107c96"
      },
      "source": [
        "co_authors_df_clear.groupby(['author_x','author_y']).size()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "author_x        author_y         \n",
              "A C Tsoi        A Sergejew           1\n",
              "                Alex Smola           1\n",
              "                Arthur Gretton       1\n",
              "                D S C So             1\n",
              "                Daniel Lowd          1\n",
              "                                    ..\n",
              "Łukasz Struski  Bartosz Zieliński    1\n",
              "                Benjamin Van Roy     1\n",
              "                Jacek Tabor          1\n",
              "                Przemysław Spurek    1\n",
              "                Xiuyuan Lu           1\n",
              "Length: 127637, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "DSdXWK3fmqNw",
        "outputId": "99b06cc3-04d2-4516-dccd-69f003c122df"
      },
      "source": [
        "n_colaborations_per_pair_df = pd.DataFrame(co_authors_df_clear.groupby(['author_x','author_y']).size()).reset_index()\n",
        "n_colaborations_per_pair_df.columns = ['author_x','author_y','n_colaborations']\n",
        "n_colaborations_per_pair_df"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author_x</th>\n",
              "      <th>author_y</th>\n",
              "      <th>n_colaborations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A C Tsoi</td>\n",
              "      <td>A Sergejew</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A C Tsoi</td>\n",
              "      <td>Alex Smola</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A C Tsoi</td>\n",
              "      <td>Arthur Gretton</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A C Tsoi</td>\n",
              "      <td>D S C So</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A C Tsoi</td>\n",
              "      <td>Daniel Lowd</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127632</th>\n",
              "      <td>Łukasz Struski</td>\n",
              "      <td>Bartosz Zieliński</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127633</th>\n",
              "      <td>Łukasz Struski</td>\n",
              "      <td>Benjamin Van Roy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127634</th>\n",
              "      <td>Łukasz Struski</td>\n",
              "      <td>Jacek Tabor</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127635</th>\n",
              "      <td>Łukasz Struski</td>\n",
              "      <td>Przemysław Spurek</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127636</th>\n",
              "      <td>Łukasz Struski</td>\n",
              "      <td>Xiuyuan Lu</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>127637 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              author_x           author_y  n_colaborations\n",
              "0             A C Tsoi         A Sergejew                1\n",
              "1             A C Tsoi         Alex Smola                1\n",
              "2             A C Tsoi     Arthur Gretton                1\n",
              "3             A C Tsoi           D S C So                1\n",
              "4             A C Tsoi        Daniel Lowd                1\n",
              "...                ...                ...              ...\n",
              "127632  Łukasz Struski  Bartosz Zieliński                1\n",
              "127633  Łukasz Struski   Benjamin Van Roy                1\n",
              "127634  Łukasz Struski        Jacek Tabor                1\n",
              "127635  Łukasz Struski  Przemysław Spurek                1\n",
              "127636  Łukasz Struski         Xiuyuan Lu                1\n",
              "\n",
              "[127637 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZN6Q09bmoiM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "azIFA-nEZmv2",
        "outputId": "d333518c-c2ef-4380-b2b7-0b194ea44e1f"
      },
      "source": [
        "n_colaborations_per_pair_df['n_colaborations'].hist()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcea6705b90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "lKzuTd8UTeqi",
        "outputId": "3937bced-b9a9-47a8-9343-a20f7b74955c"
      },
      "source": [
        "n_colaborations_per_pair_df[n_colaborations_per_pair_df['n_colaborations']>4]['n_colaborations'].hist()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcea674d190>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6cwVlKTbmD4"
      },
      "source": [
        "n_colaborations_per_pair_df.to_csv('nips_co_authors_and_colaborations.csv')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW7xvH_TaP-y"
      },
      "source": [
        "### Making graph of co authors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWewy0F0aXDl"
      },
      "source": [
        "import networkx as nx"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yssrAuFaVco"
      },
      "source": [
        "G = nx.from_pandas_edgelist(n_colaborations_per_pair_df, 'author_x', 'author_y', ['n_colaborations'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm8n0Fpvfdu7"
      },
      "source": [
        "\n",
        "#  authors charecteristics - institution, years of publishing, topic they research. cluster writers based on NLP and other results from the analysisand draw map based on cosine similarity\n",
        "#  and then project to employees. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N95WpKRho5J"
      },
      "source": [
        "# time series per writer and per institution - who emerged in the past few years? who faded? who only published once? etc, perhaps divide to 5 years"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_B7dqGcdi8_"
      },
      "source": [
        "This turns out to have far more interesting options than the one I considered so I will do graph analysis on this on a separate notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbaZIGZMinwh"
      },
      "source": [
        "## Papers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "WCl7jpX5jCRS",
        "outputId": "08b50688-e6f0-417e-aa1f-761d12c42f0f"
      },
      "source": [
        "papers_df = pd.read_csv('nips_papers/papers.csv')\n",
        "papers_df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>full_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27</td>\n",
              "      <td>1987</td>\n",
              "      <td>Bit-Serial Neural Networks</td>\n",
              "      <td>NaN</td>\n",
              "      <td>573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63</td>\n",
              "      <td>1987</td>\n",
              "      <td>Connectivity Versus Entropy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>1987</td>\n",
              "      <td>The Hopfield Model with Multi-Level Neurons</td>\n",
              "      <td>NaN</td>\n",
              "      <td>278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59</td>\n",
              "      <td>1987</td>\n",
              "      <td>How Neural Nets Work</td>\n",
              "      <td>NaN</td>\n",
              "      <td>442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69</td>\n",
              "      <td>1987</td>\n",
              "      <td>Spatial Organization of Neural Networks: A Pro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   source_id  year  ... abstract                                          full_text\n",
              "0         27  1987  ...      NaN  573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan...\n",
              "1         63  1987  ...      NaN  1 \\n\\nCONNECTIVITY VERSUS ENTROPY \\n\\nYaser  S...\n",
              "2         60  1987  ...      NaN  278 \\n\\nTHE HOPFIELD MODEL WITH MUL TI-LEVEL N...\n",
              "3         59  1987  ...      NaN  442 \\n\\nAlan  Lapedes \\nRobert  Farber \\n\\nThe...\n",
              "4         69  1987  ...      NaN  740 \\n\\nSPATIAL  ORGANIZATION  OF  NEURAL  NEn...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "rOC0-FqXjOID",
        "outputId": "1f8442ba-0dec-4429-b887-22a9c6bd87de"
      },
      "source": [
        "# papers per year bar plot\n",
        "papers_per_year_df = pd.DataFrame(papers_df['year'].value_counts()).reset_index()\n",
        "papers_per_year_df.columns = ['year','count']\n",
        "\n",
        "papers_per_year_df.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019</td>\n",
              "      <td>1428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018</td>\n",
              "      <td>1009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2017</td>\n",
              "      <td>679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016</td>\n",
              "      <td>569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014</td>\n",
              "      <td>411</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   year  count\n",
              "0  2019   1428\n",
              "1  2018   1009\n",
              "2  2017    679\n",
              "3  2016    569\n",
              "4  2014    411"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5le2P_WkYFK"
      },
      "source": [
        "papers_per_year_df_sorted = papers_per_year_df.sort_values(by = 'year',ascending=True)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "jM-Twpv6jxUi",
        "outputId": "01174743-1f19-47fa-b09d-080a1cdf99aa"
      },
      "source": [
        "a4_dims = (15, 7)\n",
        "fig, ax = plt.subplots(figsize=a4_dims)\n",
        "\n",
        "sns.set(style = \"darkgrid\", font_scale=1.3)\n",
        "ax = sns.barplot(x=\"year\", y=\"count\", data = papers_per_year_df_sorted , palette = \"GnBu_d\")\n",
        "ax.axes.set_title(\"Papers Per Year 1987-2019\",fontsize=20)\n",
        "ax.set_ylabel(\"Year\",fontsize=7)\n",
        "ax.set_xlabel(\"Number Of Papers\",fontsize=15)\n",
        "ax.set_xticklabels(papers_per_year_df_sorted['year'],rotation = 45, ha=\"right\");"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zst7xgyTnw_h"
      },
      "source": [
        "\n",
        "*   tf - idf on the titles and then sum per year/ decade/ half-decades\n",
        "*   same on abstracts\n",
        "*   same on papers.\n",
        "*   keywors extraction and comparison between years, looking for timely trends, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH2HMnH8n7Zk",
        "outputId": "686baad4-28f1-4d77-d6af-700b1de128ad"
      },
      "source": [
        "papers_df['title'].head(60)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                            Bit-Serial Neural Networks\n",
              "1                           Connectivity Versus Entropy\n",
              "2           The Hopfield Model with Multi-Level Neurons\n",
              "3                                  How Neural Nets Work\n",
              "4     Spatial Organization of Neural Networks: A Pro...\n",
              "5     A Neural-Network Solution to the Concentrator ...\n",
              "6                LEARNING BY STATE RECURRENCE DETECTION\n",
              "7                 Stability Results for Neural Networks\n",
              "8     Introduction to a System for Implementing Neur...\n",
              "9     Optimization with Artificial Neural Network Sy...\n",
              "10                  Optimal Neural Spike Classification\n",
              "11                       REFLEXIVE ASSOCIATIVE MEMORIES\n",
              "12    The Performance of Convex Set Projection Based...\n",
              "13      Speech Recognition Experiments with Perceptrons\n",
              "14    On Properties of Networks of Neuron-Like Elements\n",
              "15    Ensemble' Boltzmann Units have Collective Comp...\n",
              "16         On Tropistic Processing and Its Applications\n",
              "17    Neuromorphic Networks Based on Sparse Optical ...\n",
              "18    A 'Neural' Network that Learns to Play Backgammon\n",
              "19            Learning Representations by Recirculation\n",
              "20    A Computer Simulation of Cerebral Neocortex: C...\n",
              "21    PATTERN CLASS DEGENERACY IN AN UNRESTRICTED ST...\n",
              "22    Strategies for Teaching Layered Networks Class...\n",
              "23    Invariant Object Recognition Using a Distribut...\n",
              "24    Cycles: A Simulation Tool for Studying Cyclic ...\n",
              "25                        Learning on a General Network\n",
              "26               Neural Net and Traditional Classifiers\n",
              "27    Scaling Properties of Coarse-Coded Symbol Memo...\n",
              "28                       Synchronization in Neural Nets\n",
              "29    A NEURAL NETWORK CLASSIFIER BASED ON CODING TH...\n",
              "30    Microelectronic Implementations of Connectioni...\n",
              "31    Analysis of Distributed Representation of Cons...\n",
              "32    Hierarchical Learning Control - An Approach wi...\n",
              "33            Presynaptic Neural Information Processing\n",
              "34         An Optimization Network for Matrix Inversion\n",
              "35    Basins of Attraction for Electronic Neural Net...\n",
              "36    Programmable Synaptic Chip for Electronic Neur...\n",
              "37             Learning a Color Algorithm from Examples\n",
              "38    Generalization of Back propagation to Recurren...\n",
              "39    Neural Network Implementation Approaches for t...\n",
              "40    On the Power of Neural Networks for Solving Ha...\n",
              "41    HOW THE CATFISH TRACKS ITS PREY: AN INTERACTIV...\n",
              "42                               Phasor Neural Networks\n",
              "43            Computing Motion Using Resistive Networks\n",
              "44    Experimental Demonstrations of Optical Neural ...\n",
              "45                 MURPHY: A Robot that Learns by Doing\n",
              "46    SPONTANEOUS AND  INFORMATION-TRIGGERED SEGMENT...\n",
              "47    Simulations Suggest Information Processing Rol...\n",
              "48    An Artificial Neural Network for Spatio-Tempor...\n",
              "49    Teaching Artificial Neural Systems to Drive: M...\n",
              "50    Correlational Strength and Computational Algeb...\n",
              "51    Discovering Structure from Motion in Monkey, M...\n",
              "52    Static and Dynamic Error Propagation Networks ...\n",
              "53    Schema for Motor Control Utilizing a Network M...\n",
              "54    Distributed Neural Information Processing in t...\n",
              "55    Time-Sequential Self-Organization of Hierarchi...\n",
              "56    A Method for the Design of Stable Lateral Inhi...\n",
              "57                Constrained Differential Optimization\n",
              "58    Encoding Geometric Invariances in Higher-Order...\n",
              "59    A Novel Net that Learns Sequential Decision Pr...\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "bygXJehlol7r",
        "outputId": "b7d01f35-5f9b-4698-a47a-5d60bb97ae1a"
      },
      "source": [
        "papers_df['full_text'][0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'573 \\n\\nBIT - SERIAL NEURAL  NETWORKS \\n\\nAlan F.  Murray,  Anthony V . W.  Smith  and Zoe F.  Butler. \\n\\nDepartment of Electrical Engineering,  University of Edinburgh, \\n\\nThe King\\'s Buildings, Mayfield Road,  Edinburgh, \\n\\nScotland,  EH93JL. \\n\\nABSTRACT \\n\\nA  bit  - serial  VLSI  neural  network  is  described  from  an  initial  architecture  for  a \\nsynapse array through to silicon layout and board design.  The issues surrounding bit \\n- serial  computation,  and  analog/digital  arithmetic  are  discussed  and  the  parallel \\ndevelopment  of  a  hybrid  analog/digital  neural  network  is  outlined.  Learning  and \\nrecall  capabilities  are  reported  for  the  bit  - serial  network  along  with  a  projected \\nspecification  for  a  64  - neuron,  bit  - serial  board  operating  at 20 MHz.  This tech(cid:173)\\nnique  is  extended  to  a  256  (2562  synapses)  network  with  an  update  time  of 3ms, \\nusing  a  \"paging\"  technique  to  time  - multiplex  calculations  through  the  synapse \\narray. \\n\\n1. INTRODUCTION \\n\\nThe functions a  synthetic neural network may aspire to mimic are the ability to con(cid:173)\\nsider  many  solutions  simultaneously,  an  ability  to  work  with  corrupted  data  and  a \\nnatural  fault  tolerance.  This  arises  from  the  parallelism  and  distributed  knowledge \\nrepresentation  which  gives  rise  to  gentle  degradation  as  faults  appear.  These func(cid:173)\\ntions  are  attractive  to implementation  in VLSI  and  WSI.  For example,  the natural \\nfault  - tolerance  could  be  useful  in  silicon  wafers  with  imperfect  yield,  where  the \\nnetwork  degradation  is  approximately  proportional  to  the  non-functioning  silicon \\narea. \\nTo cast  neural networks in engineering language,  a  neuron is a  state machine that is \\neither  \"on\"  or  \"off\\',  which  in  general  assumes  intermediate  states  as  it  switches \\nsmoothly  between  these  extrema.  The  synapses  weighting  the  signals  from  a \\ntransmitting neuron  such that it is more or less excitatory or inhibitory to the receiv(cid:173)\\ning  neuron.  The  set  of synaptic weights  determines  the stable  states and  represents \\nthe learned  information in a system. \\nThe  neural  state,  VI\\'  is  related  to  the  total  neural  activity  stimulated  by  inputs  to \\nthe  neuron  through  an  activation junction,  F.  Neural  activity  is  the  level  of excita(cid:173)\\ntion  of the  neuron  and the  activation  is  the way  it  reacts  in a  response to a  change \\nin activation. The neural output state at time t, V[,  is related to x[ by \\n\\nV[  = F (xf) \\n\\n(1) \\n\\nThe  activation  function  is  a  \"squashing\"  function  ensuring  that  (say)  Vi  is  1  when \\nXi  is large  and  -1  when Xi  is  small.  The neural update function  is therefore straight(cid:173)\\nforward: \\n\\n. \\n\\n,+1  - ,   + ~  ~ T  V\\' \\nJ \\nXI \\n\\ni-n-l \\n0  ~  ii \\n\\n- XI \\n\\n• •••• \\n\\nJ-O \\n\\n(2) \\n\\nwhere  8  represents  the  rate  of change  of neural  activity,  Tij \\nand n  is  the number of terms giving an n  - neuron array [1]. \\nAlthough  the  neural function  is  simple  enough,  in  a  totally  interconnected  n  - neu(cid:173)\\nron  network  there  are n 2  synapses requiring n 2  multiplications  and  summations and \\n\\nis  the  synaptic  weight \\n\\n© American Institute of Physics 1988 \\n\\n\\x0c574 \\n\\na large number of interconnects.  The challenge in VLSI is therefore to design a  sim(cid:173)\\nple,  compact  synapse  that  can  be  repeated  to  build  a  VLSI  neural  network  with \\nIn  a  network  with  fixed  functionality,  this  is  relatively \\nmanageable  interconnect. \\nstraightforward.  H the  network  is to be able to learn,  however,  the synaptic weights \\nmust  be programmable, and therefore more complicated. \\n\\n2. DESIGNING  A NEURAL  NETWORK IN  VLSI \\n\\nThere  are  fundamentally  two  approaches  to  implementing  any  function  in  silicon  -\\ndigital and analog.  Each technique has its advantages and  disadvantages,  and these \\nare  listed  below,  along  with  the  merits  and  demerits  of bit  - serial  architectures  in \\ndigital (synchronous) systems. \\nDigital  vs.  analog:  The  primary  advantage  of digital  design  for  a  synapse  array  is \\nthat  digital  memory  is  well  understood,  and  can  be  incorporated  easily.  Learning \\nnetworks are  therefore  possible  without  recourse  to unusual  techniques  or technolo(cid:173)\\ngies.  Other strengths of a digital approach are that design techniques are advanced, \\nautomated  and  well  understood  and  noise  immunity  and  computational  speed  can \\nbe  high.  Unattractive features  are  that  digital  circuits  of this complexity need  to  be \\nsynchronous  and  all  states  and  activities  are  quantised,  while  real  neural  networks \\nare  asynchronous  and  unquantised.  Furthermore,  digital  multipliers  occupy  a  large \\nsilicon  area, giving a low synapse count on  a single chip. \\nThe  advantages  of  analog  circuitry  are  that  asynchronous  behaviour  and  smooth \\nneural  activation  are  automatic.  Circuit  elements can  be  small,  but  noise  immunity \\nis relatively  low  and  arbitrarily  high  precision is not  possible.  Most  importantly,  no \\nreliable  analog,  non  - volatile  memory  technology  is  as  yet  readily  available.  For \\nthis  reason,  learning  networks  lend  themselves  more  naturally to  digital  design  and \\nimplementation. \\nSeveral  groups  are  developing  neural  chips  and  boards,  and  the  following  listing \\ndoes  not  pretend  to  be  exhaustive.  It is  included,  rather,  to indicate  the spread  of \\nactivity  in  this  field.  Analog  techniques  have  been  used  to  build  resistor  I  opera(cid:173)\\ntional  amplifier  networks [2,3]  similar to  those  proposed  by  Hopfield  and Tank [4]. \\nA  large  group  at  Caltech  is  developing  networks  implementing  early  vision  and \\nauditory  processing  functions  using the intrinsic nonlinearities of MaS transistors in \\nthe subthreshold  regime  [5,6].  The problem of implementing analog  networks with \\nelectrically  programmable  synapses  has  been  addressed  using  CCDIMNOS technol(cid:173)\\nogy  [7].  Finally,  Garth  [8]  is  developing  a  digital  neural  accelerator  board  (\"Net(cid:173)\\nsim\")  that  is  effectively  a  fast  SIMD  processor  with  supporting  memory  and  com(cid:173)\\nmunications chips. \\nBit - serial  vs.  bit  - parallel:  Bit  - serial  arithmetic and  communication  is  efficient \\nfor  computational  processes,  allowing  good  communication  within  and  between \\nVLSI  chips  and  tightly  pipelined  arithmetic  structures.  It  is  ideal  for  neural  net(cid:173)\\nworks  as  it  minimises  the  interconnect  requirement  by  eliminating  multi  - wire \\nbusses.  Although  a  bit  - parallel  design  would  be  free  from  computational  latency \\n(delay  between  input  and  output),  pipelining  makes  optimal  use  of  the  high  bit  -\\nrates possible in serial systems,  and  makes for  efficient circuit usage. \\n2.1  An asynchronous pulse stream VLSI neural network: \\nIn  addition  to  the  digital  system  that  forms  the  substance  of  this  paper,  we  are \\ndeveloping  a  hybrid  analOg/digital  network  family.  This work  is  outlined  here,  and \\nhas  been  reported  in  greater  detail  elsewhere  [9, 10, 11].  The  generic  (logical  and \\nlayout)  architecture  of a  single  network  of n  totally  interconnected neurons is  shown \\n\\n\\x0c575 \\n\\nschematically  in  figure  1.  Neurons  are  represented  by  circles,  which  signal  their \\nstates,  Vi  upward  into  a  matrix  of  synaptic  operators.  The  state  signals  are  con(cid:173)\\nnected  to  a  n  - bit  horizontal  bus  running  through  the  synaptic  array,  with  a  con(cid:173)\\nnection  to  each  synaptic  operator  in  every  column.  All  columns  have  n  operators \\n(denoted  by  squares)  and  each  operator adds its synaptic contribution,  Tij V j\\n,  to the \\nrunning  total  of  activity  for  the  neuron  i  at  the  foot  of  the  column.  The  synaptic \\nfunction  is  therefore  to  multiply  the  signalling  neuron  state,  Vj\\n,  by  the  synaptic \\nweight,  Tij ,  and  to  add  this  product  to  the  running  total.  This  architecture  is com(cid:173)\\nmon to both  the bit - serial and pulse - stream networks. \\n\\nSynapse \\n\\nStates { Vj  } \\n\\nFigure 1. Generic architecture for  a  network of n totally interconnected neurons. \\n\\nNeurons \\n\\nj=O \\n\\nj=II -1 \\n\\nThis type of architecture has many attractions for  implementation in 2  - dimensional \\nsilicon  as  the  summation  2  Tij Vj  is  distributed  in  space.  The  interconnect \\nrequirement  (n  inputs  to  each  neuron)  is  therefore  distributed  through  a  column, \\nreducing the need  for  long - range wiring.  The architecture is modular,  regular and \\ncan be easily expanded. \\nIn  the  hybrid  analog/digital  system,  the  circuitry  uses  a  \"pulse  stream\"  signalling \\nmethod  similar  to  that  in  a  natural  neural  system.  Neurons  indicate  their  state  by \\nthe  presence  or  absence  of  pulses  on  their  outputs,  and  synaptic  weighting  is \\nachieved  by  time  - chopping  the  presynaptic  pulse  stream  prior  to  adding  it  to  the \\npostsynaptic  activity  summation.  It  is  therefore  asynchronous  and  imposes  no fun(cid:173)\\ndamental  limitations  on  the  activation  or  neural  state.  Figure  2  shows  the  pulse \\nstream  mechanism  in  more  detail.  The synaptic  weight  is  stored  in  digital  memory \\nlocal to the operator.  Each synaptic operator has an  excitatory and inhibitory  pulse \\nstream  input  and  output.  The  resultant  product  of  a  synaptic  operation,  Tij Vj\\n,  is \\nadded  to  the  running  total  propagating  down  either  the  excitatory  or  inhibitory \\nchannel.  One binary bit  (the  MSBit)  of the  stored  Tij  determines whether  the con(cid:173)\\ntribution  is excitatory or inhibitory. \\nThe  incoming  excitatory  and  inhibitory  pulse  stream  inputs  to  a  neuron  are \\nintegrated  to  give  a  neural  activation  potential  that varies  smoothly  from  0  to  5  V. \\nThis  potential controls a  feedback  loop with  an odd number of logic  inversions and \\n\\n\\x0c576 \\n\\n. • • \\n\\nXT •• \\n\\nV , \\n.u.u, \\n• \\n\\nFigure  2.  Pulse  stream  arithmetic.  Neurons  are  denoted  by  0  and synaptic  operators \\nby  D. \\n\\nthus  forms  a  switched  \"ring - oscillator\".  H the inhibitory input dominates,  the feed(cid:173)\\nback  loop  is  broken.  H  excitatory  spikes  subsequently  dominate  at  the  input,  the \\nneural activity rises  to 5V and the feedback  loop oscillates with  a period determined \\nby a  delay  around  the loop.  The resultant  periodic waveform is then converted to a \\nseries  of voltage  spikes,  whose  pulse  rate  represents  the  neural  state,  Vi\\'  Interest(cid:173)\\ningly,  a  not  dissimilar  technique is  reported  elsewhere  in this volume,  although  the \\nsynapse function  is executed differently [12]. \\n\\n3. A 5  - STATE BIT - SERIAL NEURAL  NETWORK \\n\\nThe  overall  architecture  of  the  5  - state  bit  - serial  neural  network  is  identical  to \\nthat  of  the  pulse  stream  network.  It  is  an  array  of n 2  interconnected  synchronous \\nsynaptic  operators,  and  whereas  the  pulse  stream  method  allowed  Vj  to  assume  all \\nvalues  between  \"off\\' and  \"on\",  the  5 - state network VJ  is constrained  to 0,  ±0.5 Qr \\n± 1.  The resultant  activation  function  is  shown  in  Figure 3.  Full  digital  multiplica(cid:173)\\ntion  is  costly  in  silicon  area,  but  multiplication  of  Tij  by  Vj  =  0.5  merely  requires \\nthe synaptic  weight  to be right  - shifted  by  1 bit.  Similarly,  multiplication  by  0.25 \\ninvolves  a  further  right  - shift  of Til\\'  and  multiplication  by 0.0  is  trivially  easy.  VJ \\n<  0 is not  problematic,  as  a  switchable adder/subtractor  is  not much  more complex \\nthan  an  adder.  Five  neural  states  are  therefore  feasible  with  circuitry  that  is  only \\nslightly more complex  than  a  simple serial adder.  The neural state expands from a  1 \\nbit  to  a  3  bit  (5  - state)  representation,  where  the  bits  represent  \"add/subtract?\", \\n\"shift?\" and \"multiply by O?\". \\nFigure 4  shows  part of the synaptic  array.  Each synaptic operator includes an 8 bit \\nshift  register  memory  block  holding  the  synaptic  weight,  Til\\'  A  3  bit  bus  for  the  5 \\nneural  states  runs  horizontally  above  each  synaptic  row.  Single  phase  dynamic \\nCMOS  has  been  used  with  a  clock  frequency  in  excess  of 20  MHz  [13).  Details of \\na synaptic operator are  shown  in  figure 5.  The synaptic weight  Til  cycles around the \\nshift  register  and  the  neural  state  Vj  is  present  on  the  state  bus.  During  the  first \\nclock  CYCle,  the  synaptic  weight  is  multiplied  by  the  neural  state  and  during  the \\nsecond,  the  most  significant  bit (MSBit)  of the resultant  Tij Vj  is sign  - extended for \\n\\n\\x0c577 \\n\\nlHRESHOLD \\n\\nState VJ \\n\\n..... -------=-------.. Activity sJ \\n\\ns· \\n\\n\"5  STATE\" \\n\\n\"Sharper\" \\n\\n\"Smoother\" \\n\\n~.....::~-\"\\'--x.&..t------ Activity \"J \\n\\nFigure 3.  \"Hard - threshold\",  5  - state and sigmoid activation functions. \\n\\nJ-a-1T  v \\n~  ..  J \\nJ-li \\n\\nv, \\n\\nv, \\n\\nFigure 4.  Section  of the  synaptic  array  of the  5  - state activation function  neural net(cid:173)\\nwork. \\n\\n8  bits  to  allow  for  word  growth  in  the  running  summation.  A  least  significant  bit \\n(LSBit)  signal  running down  the  synaptic  columns indicates the arrival  of the LSBit \\nof  the  Xj  running  total.  If  the  neural  state  is  ±O.5  the  synaptic  weight  is  right \\nshifted  by  1 bit and then added to or subtracted from  the running total.  A  multipli(cid:173)\\ncation  of  ± 1  adds  or  subtracts  the  weight  from  the  total  and  multiplication  by  0 \\n\\n\\x0c578 \\n\\n.0.5 \\n.0.0 \\n\\nAdd/Subtract \\n\\nAdd! \\nSubtract \\n\\nCarry \\n\\nFigure S.  The  synaptic operator with a 5 - state activation function. \\n\\ndoes not alter the running summation. \\nThe  final  summation  at  the  foot  of the  column  is  thresholded  externally  according \\nto  the  5  - state activation function  in  figure  3.  As  the  neuron activity Xj\\'  increases \\nthrough  a  threshold  value  x\" \\nideal  sigmoidal  activation  represents  a  smooth  switch \\nof  neural  state  from  -1  to  1.  The 5  - state  \"staircase\"  function  gives a  superficially \\nmuch  better  approximation  to  the  sigmoid  form  than  a  (much  simpler  to  imple(cid:173)\\nment)  threshold  function.  The  sharpness  of  the  transition  can  be  controlled  to \\n\"tune\"  the  neural dynamics for  learning and computation.  The control parameter is \\nreferred  to  as  temperature  by  analogy  with  statistical  functions  with  this  sigmoidal \\nform.  High  \"temperature\" gives a  smoother staircase and sigmoid,  while a tempera(cid:173)\\nture  of  0  reduces  both  to  the  \\'\\'Hopfield\\'\\'  - like  threshold  function.  The  effects  of \\ntemperature  on  both  learning  and  recall  for  the  threshold  and  5  - state  activation \\noptions are discussed in section 4. \\n\\n4. LEARNING AND  RECALL  WITH VLSI  CONSTRAINTS \\n\\nBefore  implementing  the  reduced  - arithmetic  network  in  VLSI,  simulation  experi(cid:173)\\nments  were  conducted  to  verify  that  the  5  - state  model  represented  a  worthwhile \\nenhancement  over  simple  threshold  activation.  The  \"benchmark\"  problem  was \\nchosen  for  its  ubiquitousness,  rather  than  for  its  intrinsic  value.  The  implications \\nfor  learning  and  recall  of the  5  - state  model,  the  threshold  (2  - state)  model  and \\n- state)  were  compared  at  varying  temperatures \\nsmooth  sigmoidal  activation  (  00 \\nIn  each  simulation  a  totally \\nwith  a  restricted  dynamic  range  for  the  weights  Tij • \\ninterconnected  64  node  network  attempted  to  learn  32  random  patterns  using  the \\ndelta  rule  learning  algorithm  (see  for  example  [14]).  Each  pattern  was  then  cor(cid:173)\\nrupted  with  25%  noise  and  recall  attempted  to  probe  the  content  addressable \\nmemory properties under the three different activation options. \\nDuring  learning,  individual  weights  can  become  large  (positive  or  negative).  When \\nweights  are  \"driven\"  beyond  the  maximum  value  in  a  hardware  implementation, \\n\\n\\x0c579 \\n\\nwhich  is  determined  by  the  size  of  the  synaptic  weight  blocks,  some  limiting \\nmechanism  must  be  introduced.  For  example,  with  eight  bit  weight  registers,  the \\nlimitation is  -128  S  Tij  S  127.  With integer weights,  this can be seen to be a prob(cid:173)\\nlem  of  dynamic  range,  where  it  is  the  relationship  between  the  smallest  possible \\nweight  (± 1) and the largest  (+ 127/-128) that is the issue. \\nResults:  Fig.  6  shows  examples  of the  results  obtained,  studying  learning  using  5  -\\nstate  activation  at  different  temperatures,  and  recall  using  both  5  - state  and  thres(cid:173)\\nhold  activation.  At  temperature  T=O,  the  5  - state  and  threshold  models  are \\ndegenerate,  and  the results identical.  Increasing smoothness of activation  (tempera(cid:173)\\nture)  during  learning  improves  the  quality  of  learning  regardless  of  the  activation \\nfunction  used  in  recall,  as more patterns are recognised  successfully.  Using 5 - state \\nactivation  in recall  is more effective  than simple  threshold  activation.  The effect of \\ndynamic  range  restrictions  can  be  assessed  from  the  horizontal  axis,  where  T/j:6.  is \\nshown.  The results  from  these and  many  other experiments may  be  summarised  as \\nfollows:-\\n5 - State activation  vs.  threshold: \\n1)  Learning with 5  - state activation was  protracted  over the threshold  activation, \\nas  binary  patterns  were  being  learnt,  and  the  inclusion  of  intermediate  values \\nadded extra degrees of freedom. \\n\\n2)  Weight  sets  learnt  using  the  5  - state  activation  function  were  \"better\"  than \\nthose  learnt  via  threshold  activation,  as  the  recall  properties  of both  5  - state \\nand  threshold  networks  using  such  a  weight  set  were  more  robust  against \\nnoise. \\nFull  sigmoidal  activation  was  better  than  5  - state,  but  the  enhancement  was \\nless  significant  than  that  incurred  by  moving  from  threshold  - 5 - state.  This \\nsuggests  that the law  of diminishing returns  applies to  addition of levels to the \\nneural  state  Vi\\'  This  issue  has  been  studied  mathematically  [15],  with  results \\nthat agree  qualitatively with  ours. \\n\\n3) \\n\\nWeight Saturation: \\nThree  methods  were  tried  to  deal  with  weight  saturation.  Firstly,  inclusion  of  a \\ndecay,  or  \"forgetting\"  term  was  included  in  the  learning  cycle  [1].  It  is  our  view \\nthat  this  technique can  produce the desired weight limiting property,  but in  the time \\navailable  for  experiments,  we  were  unable  to  \"tune\"  the  rate  of  decay  sufficiently \\nwell  to  confirm  it.  Renormalisation  of the  weights  (division  to  bring large  weights \\nback  into  the  dynamic  range)  was  very  unsuccessful,  suggesting  that  information \\ndistributed  throughout  the  numerically small  weights  was  being  destroyed.  Finally, \\nthe  weights were  allowed  to  \"clip\"  (ie any weight  outside the dynamic range  was  set \\nto  the  maximum  allowed  value).  This method  proved  very  successful,  as  the learn(cid:173)\\ning  algorithm  adjusted the weights  over which  it still  had control  to  compensate for \\nthe  saturation effect.  It is  interesting to note  that  other experiments have indicated \\nthat  Hopfield  nets  can  \"forget\"  in a  different  way,  under different learning control, \\ngiving  preference  to  recently acquired  memories [16].  The results  from  the  satura(cid:173)\\ntion experiments were:-\\n1) \\n\\nFor  the  32  pattemJ64  node  problem,  integer  weights  with  a  dynamic  range \\ngreater than  ±30 were necessary to give enough  storage capability. \\nFor weights  with  maximum  values  TiJ  = 50-70,  \"clipping\"  occurs,  but  net(cid:173)\\nwork  performance  is  not  seriously  degraded  over  that  with  an  unrestricted \\nweight set. \\n\\n2) \\n\\n\\x0c580 \\n\\n15 \\n\\n\"0  10 \\nc = \\n.2 \\nen e u \\n5 --~ \\n\\n0 \\n\\n0 \\n\\nI \\n\\n\".\\' \\n\\n., ... \\n\\n.... ----------\\n\\n,-\\ne  ~ ;A ....... ;.. f:\\'-:\\' :::::7.:::.::-:::-: f\\'-. \\n,  ,. \\ni \\n! \\n! , \\ni \\nI \\nI , \\n\\n20  30 \\n\\n40  50  60  70 \\n\\nLimit \\n\\n15 \\n\\nT=30  _._.-.-\\nT=20 \\nT=10 \\nT=O \\n\\n-.-._.-.. \\n\\n,.. .•. -..... -.•. _ .•. \\n, \\n.. \\ni \\nj\\'\\'\\'\\'--\\n,,\\'i \\n\\n- . . .,. \\'\" \\n\\nj \\n\\n~-------------\\n••••••• •••••••••••••••• •••••• \\n\\nj \\nI \\n\\nO~~~~--~~ __ ~~ __ \\no \\n\\n20  30  40  50  60  70 \\n\\nLimit \\n\\n5 . state activation function  recal1 \\n\\ntlHopficld\" activation  function  recall \\n\\nFigure 6.  Recall  of patterns  learned  with  the  5  .  state  activation function  and  subse(cid:173)\\nquently restored using  the 5-state and the  hard - threshold activation functions. \\nT  is  the  \"temperature\",  or smoothness  of the  activation function,  and \"limit\"  the  value \\nofTI; ·  \\n\\nThese  results  showed  that  the  5  - state  model  was  worthy  of implementation  as  a \\nVLSI neural board, and suggested that 8 - bit weights were sufficient. \\n\\nS.  PROJECTED SPECIFICATION OF A HARDWARE NEURAL  BOARD \\n\\nThe specification of a  64  neuron board is  given  here,  using a  5 - state bit  - serial 64 \\nx 64  synapse array with  a derated clock speed  of 20 MHz.  The synaptic weights are \\n8  bit words and the word  length  of the running summation XI  is  16  bits to  allow for \\ngrowth.  A  64  synapse  column  has  a  computational  latency  of  80  clock  cycles  or \\nbits,  giving  an  update  time  of 4 .... s  for  the  network.  The  time  to  load  the  weights \\ninto  the  array  is  limited  to  6O .... s  by  the  supporting  RAM,  with  an  access  time  of \\n12Ons.  These  load  and  update  times  mean  that  the  network  is  executing  1  x  10\\' \\noperations/second,  where  one  operation  is  ±  Tlj  Vj •  This  is  much  faster  than  a \\nnatural  neural  network,  and  much  faster  than  is  necessary  in  a  hardware  accelera(cid:173)\\ntor.  We  have  therefore  developed  a  \"paging\"  architecture,  that  effectively  \"trades -\\noff\" some of this excessive speed against increased network size. \\nA  \"moving  - patch\"  neural  board:  An  array  of  the  5  - state  synapses  is  currently \\nbeing  fabricated  as  a  VLSI  integrated  circuit.  The  shift  registers  and \\nthe \\nadderlsubtractor for  each  synapse  occupy a  disappointingly large silicon  area,  allow(cid:173)\\ning only a  3  x 9 synaptic  array.  To achieve  a  suitable size  neural  network  from  this \\narray,  several chips need to be  included on a  board with  memory and control circu(cid:173)\\nitry.  The  \"moving  patch\"  concept  is  shown  in  figure  7,  where  a  small  array  of \\nsynapses is passed over a much larger n  x n  synaptic array. \\nEach  time  the  array  is  \"moved\"  to  represent  another set  of  synapses,  new  weights \\nmust be  loaded  into it.  For example,  the  first  set of weights will  be T 11  •. ,  T;J  ... T 21 \\n...  T 2j  to Tjj ,  the second  set  Tj + 1,l  to T u  etc..  The final  weight  to be loaded will  be \\n\\n\\x0c581 \\n\\nn  neurons .. om synaptic array \\n\\nSmaller \"Patch\" \\n\\nmoves over array \\n\\nrr~ _____ ) __ -.. \\n> \\n~\\'-\\n\\nFigure 7.  The  \"moving  patch\" concept,  passing  a  small synaptic \"patch\"  over  a larger \\nrun synapse array. \\n\\nTNt·  Static,  off - the  - shelf RAM is  used  to store the weights and the  whole opera(cid:173)\\ntion  is  pipelined for  maximum efficiency.  Figure 8 shows the board level design for \\nthe network. \\n\\nSynaptic  Accelerator Chips \\n\\nControl \\n\\nHOST \\nFigure 8. A  \"moving  patch\" neural network board. \\n\\nThe small  \"patch\" that moves  around  the array  to  give  n  neurons comprises 4 VLSI \\nsynaptic accelerator chips to give  a 6 x 18 synaptic array. The number of neurons to \\nbe  simulated  is 256  and  the weights for  these  are stored  in 0.5  Mb of RAM  with a \\nload  time  of 8ms.  For  each  \"patch\"  movement,  the  partial  runnin~ summatinn \\n\\n;. \\n\\n\\x0c582 \\n\\ncalculated  for  each  column,  is  stored  in  a  separate  RAM  until  it is  required  to  be \\nadded  into  the  next  appropriate  summation.  The  update  time  for  the  board  is  3ms \\ngiving  2  x  107  operations/second.  This  is  slower  than  the  64  neuron  specification, \\nbut  the  network  is  16  times  larger,  as  the  arithmetic  elements are  being  used  more \\nefficiently.  To  achieve  a  network  of  greater  than  256  neurons,  more  RAM  is \\nrequired to store the weights.  The network is then slower unless a larger number of \\naccelerator chips is  used  to give  a larger moving \"patch\". \\n\\n6.  CONCLUSIONS \\n\\nA  strategy  and  design  method  has  been  given  for  the  construction  of  bit  - serial \\nVLSI neural network chips and  circuit  boards.  Bit - serial  arithmetic,  coupled  to  a \\nreduced  arithmetic  style,  enhances  the  level  of  integration  possible  beyond  more \\nconventional digital,  bit - parallel schemes.  The restrictions imposed  on both synap(cid:173)\\ntic  weight  size  and  arithmetic  precision  by  VLSI  constraints  have  been  examined \\nand shown to be tolerable,  using the associative memory problem as a test. \\nWhile  we  believe  our  digital  approach  to  represent  a  good  compromise  between \\narithmetic  accuracy  and  circuit  complexity,  we  acknowledge  that  the  level  of \\nintegration  is  disappointingly  low. \\nIt  is  our  belief  that,  while  digital  approaches \\nmay  be interesting and  useful  in the medium  term,  essentially as  hardware accelera(cid:173)\\ntors for  neural simulations,  analog techniques represent the best  ultimate option in 2 \\n- dimensional  silicon.  To this  end,  we  are currently pursuing techniques for  analog \\nIn any  event,  the  full \\npseudo  - static  memory,  using  standard  CMOS  technology. \\ndevelopment  of a  nonvolatile  analog  memory  technology,  such  as  the  MNOS  tech(cid:173)\\nnique [7],  is key to the long - term  future of VLSI neural nets that can learn. \\n\\n7. ACKNOWLEDGEMENTS \\n\\nThe  authors  acknowledge  the  support  of  the  Science  and  Engineering  Research \\nCouncil (UK) in the execution of this work. \\n\\nReferences \\n\\n1. \\n\\nS.  Grossberg,  \"Some  Physiological  and  Biochemical  Consequences  of Psycho(cid:173)\\nlogical Postulates,\" Proc.  Natl.  Acad.  Sci.  USA,  vol.  60,  pp.  758  - 765,  1968. \\n\\n2.  H.  P.  Graf,  L.  D.  Jackel,  R.  E.  Howard,  B.  Straughn,  J.  S.  Denker,  W. \\nHubbard,  D.  M.  Tennant,  and  D.  Schwartz,  \"VLSI  Implementation  of  a \\nNeural  Network  Memory  with  Several  Hundreds  of  Neurons,\"  Proc.  AlP \\nConference on Neural Networks for  Computing.  Snowbird,  pp.  182 - 187,  1986. \\n3.  W.  S.  Mackie,  H.  P.  Graf,  and  J.  S.  Denker,  \"Microelectronic  Implementa(cid:173)\\n\\ntion  of  Connectionist  Neural  Network  Models,\"  IEEE  Conference  on  Neural \\nInformation Processing Systems.  Denver,  1987. \\nJ . J. Hopfield  and D.  W.  Tank, \"Neural\" Computation of Decisions in  Optim(cid:173)\\nisation Problems,\" BioI.  Cybern.,  vol.  52,  pp.  141  - 152,  1985. \\n\\n4. \\n\\n5.  M.  A.  Sivilotti,  M.  A.  Mahowald,  and  C.  A.  Mead, Real - Time  Visual Com(cid:173)\\n\\nputations Using  Analog CMOS  Processing Arrays, 1987.  To be published \\n\\n6.  C.  A.  Mead,  \"Networks  for  Real  - Time  Sensory  Processing,\"  IEEE  Confer(cid:173)\\n\\nence  on  Neural Information  Processing Systems,  Denver,  1987. \\n\\n\\x0c583 \\n\\n7. \\n\\n8. \\n\\nJ.  P.  Sage,  K.  Thompson.  and  R. S.  Withers,  \"An Artificial Neural  Network \\nIntegrated  Circuit  Based on MNOSlCCD  Principles,\"  Proc. AlP Conference on \\nNeural Networlcs for Computing,  Snowbird,  pp.  381  - 385,  1986. \\nS.  C.  J.  Garth, \"A Chipset for  High Speed  Simulation of Neural Network  Sys(cid:173)\\ntems,\"  IEEE Conference on Neural Networlc.s,  San Diego,  1987. \\n\\n9.  A.  F.  Murray and  A.  V.  W.  Smith,  \"A Novel  Computational  and  Signalling \\nMethod  for  VLSI Neural Networks,\"  European  Solid State Circuits Conference \\n, 1987. \\n\\n10.  A.  F.  Murray  and  A.  J.  W.  Smith,  \"Asynchronous  Arithmetic  for  VLSI \\n\\nNeural Systems,\"  Electronics Letters, vol.  23, no.  12, p.  642, June, 1987. \\n\\n11.  A.  F.  Murray  and  A.  V.  W.  Smith,  \"Asynchronous  VLSI  Neural  Networks \\n\\nusing  Pulse  Stream  Arithmetic,\"  IEEE  Journal  of Solid-State  Circuits  and Sys(cid:173)\\ntems,  1988.  To be published \\n\\n12.  M.  E.  Gaspar,  \"Pulsed  Neural  Networks:  Hardware,  Software  and  the  Hop(cid:173)\\nfield  AID  Converter  Example,\"  IEEE  Conference  on  Neural  Information  Pro(cid:173)\\ncessing Systems.  Denver,  1987. \\n\\n13.  M.  S.  McGregor,  P.  B.  Denyer,  and A.  F.  Murray,  \"A Single - Phase  Clock(cid:173)\\ning Scheme for  CMOS  VLSI,\"  Advanced Research  in  VLSI  \" Proceedings of the \\n1987 Stanford Conference,  1987. \\n\\n14.  D.  E.  Rumelhart,  G.  E.  Hinton,  and  R.  J.  Williams,  \"Learning  Internal \\nRepresentations  by  Error  Propagation,\"  Parallel  Distributed  Processing  \" \\nExplorations  in  the  Microstructure of Cognition,  vol.  1,  pp.  318 - 362,  1986. \\n\\n15.  M.  Fleisher  and  E.  Levin,  \"The  Hopfiled  Model  with  Multilevel  Neurons \\nModels,\"  IEEE  Conference  on  Neural  Information  Processing  Systems.  Denver, \\n1987. \\n\\n16.  G.  Parisi,  \"A  Memory  that  Forgets,\"  J.  Phys.  A  .\\'  Math.  Gen.,  vol.  19,  pp. \\n\\nL617  - L620,  1986. \\n\\n\\x0c'"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTZn9jhfpKSy"
      },
      "source": [
        "\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vin_7UtuGK0P"
      },
      "source": [
        "# Text Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwPl3lEeGJpp"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xn3UTnyGPi8"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cetC844PGN-p"
      },
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Doc cleaning\"\"\"\n",
        "    \n",
        "    # Lowering text\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Removing punctuation\n",
        "    text = \"\".join([c for c in text if c not in PUNCTUATION])\n",
        "    \n",
        "    # Removing whitespace and newlines\n",
        "    text = re.sub('\\s+',' ',text)\n",
        "    \n",
        "    return text\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzEkqc-kGJsj"
      },
      "source": [
        "PUNCTUATION = \"\"\"!\"#$%&'()*+,-/:;<=>?@[\\]^_`{|}~\"\"\" # excluding . (full-stop) from the set of punctuations\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC3qUMj4GJwC",
        "outputId": "52401574-0bca-41ca-9711-c464b433bacb"
      },
      "source": [
        "papers_df.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9680, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQVDHmSNGJy8",
        "outputId": "1c987750-0a81-480a-82ce-32ea3957a5c4"
      },
      "source": [
        "papers_df.dropna(subset=['full_text'], inplace=True)\n",
        "papers_df.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9677, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hffrGYDGJ2j"
      },
      "source": [
        "papers_df['full_text_clean'] = papers_df['full_text'].apply(lambda row: clean_text(row))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "AWNMGbuQGJ5M",
        "outputId": "1da1f1a9-5482-42b5-a5de-d768a5f631d0"
      },
      "source": [
        "papers_df['full_text_clean'][3]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'442 alan lapedes robert farber theoretical division how neural nets work los alamos national laboratory los alamos nm 87545 abstract there is presently great interest in the abilities of neural networks to mimic qualitative reasoning by manipulating neural incodings of symbols. less work has been performed on using neural networks to process floating point numbers and it is sometimes stated that neural networks are somehow inherently inaccucid173 rate and therefore best suited for fuzzy qualitative reasoning. nevertheless the potential speed of massively parallel operations make neural net number crunching an interesting topic to explore. in this paper we discuss some of our work in which we demonstrate that for certain applications neural networks can achieve significantly higher numerical accuracy than more conventional techcid173 niques. in particular prediction of future values of a chaotic time series can be performed with exceptionally high accuracy. we analyze how a neural net is able to do this and in the process show that a large class of functions from rn. rffl may be accurately approximated by a backpropagation neural net with just two hidden layers. the network uses this functional approximation to perform either interpolation signal processing applications or extrapolation symbol processing applicationsj. neural nets therefore use quite familiar methcid173 ods to perform. their tasks. the geometrical viewpoint advocated here seems to be a useful approach to analyzing neural network operation and relates neural networks to well studied topics in functional approximation. 1. introduction although a great deal of interest has been displayed in neural networks capabilities to perform a kind of qualitative reasoning relatively little work has been done on the ability of neural networks to process floating point numbers in this in a massively parallel fashion. clearly this is an important ability. paper we discuss some of our work in this area and show the relation between numerical and symbolic processing. we will concentrate on the the subject of accurate prediction in a time series. accurate prediction has applications in many areas of signal processing. it is also a useful and fascinating ability when dealing with natural physical systems. given some .data from the past history of a system can one accurately predict what it will do in the future many conventional signal processing tests such as correlation function analcid173 ysis cannot distinguish deterministic chaotic behavior from from stochastic noise. particularly difficult systems to predict are those that are nonlinear and chaotic. chaos has a technical definition based on nonlinear dynamical systems theory but intuitivly means that the system is deterministic but random in a rather similar manner to deterministic pseudo random number generators used on conventional computers. examples of chaotic systems in nature include turbulence in fluids d. ruelle 1971 h. swinney 1978 chemical reactions k. tomita 1979 lasers h. haken 1975 plasma physics d. russel 1980 to name but a few. typically chaotic systems also display the full range of noncid173 linear behavior fixed points limit cycles etc. when parameters are varied and therefore provide a good testbed in which to investigate techniques of nonlinear signal processing. clearly if one can uncover the underlying deterministic alcid173 gorithm from a chaotic time series then one may be able to predict the future time series quite accurately © american institute of physics 1988 443 in this paper we review and extend our work lapedes and farber 1987 on predicting the behavior of a particular dynamical system the glassmackey equation. we feel that the method will be fairly general and use the glasscid173 mackey equation solely for illustrative purposes. the glassmackey equation has a strange attractor with fractal dimension controlled by a constant paramcid173 eter appearing in the differential equation. we present results on a neural netcid173 works ability to predict this system at two values of this parameter one value corresponding to the onset of chaos and the other value deeply in the chaotic regime. we also present the results of more conventional predictive methods and show that a neural net is able to achieve significantly better numerical accuracy. this particular system was chosen because of d. farmers and j. sidorowichs d. farmer j . sidorowich 1987 use of it in developing a new nonneural net method for predicting chaos. the accuracy of this nonneural net method and the neural net method are roughly equivalent with various advantages or discid173 advantages accruing to one method or the other depending on ones point of view. we are happy to acknowledge many valuable discussions with farmer and sidorowich that has led to further improvements in each method. we also show that a neural net never needs more than two hidden layers to solve most problems. this statement arises from a more general argument that a neural net can approximate functions from rn. rm with only two hidden layers and that the accuracy of the approximation is controlled by the number of neurons in each layer. the argument assumes that the global minimum to the backpropagation minimization problem may be found or that a local minima very close in value to the global minimum may be found. this seems to be the case in the examples we considered and in many examples considered by other researchers but is never guaranteed. the conclusion of an upper bound of two hidden layers is related to a similar conclusion of r. lipman r. lipman 1987 who has previously analyzed the number of hidden layers needed to form arbitrary decision regions for symbolic processing problems. related issues are discussed by j. denker j. denker et.al. 1987 it is easy to extend the argument to draw similar conclusions about an upper bound of two hidden layers for symbol processing and to place signal processing and symbol processing in a common theoretical framework. 2. backpropagation backpropagation is a learning algorithm for neural networks that seeks to find weights t ij such that given an input pattern from a training set of pairs of inputoutput patterns the network will produce the output of the training set given the input. having learned this mapping between i and 0 for the training set one then applies a new previously unseen input and takes the output as the conclusion drawn by the neural net based on having learned fundamental relationships between input and output from the training set. a popular configuration for backpropagation is a totally feedforward net figure 1 where input feeds up through hidden layers to an output layer. 444 output figure 1. a feedforward neural net. arrows schematcid173 ically indicate full feedforward connectcid173 ivity each neuron forms a weighted sum of the inputs from previous layers to which it is connected adds a threshold value and produces a nonlinear function of this sum as its output value. this output value serves as input to the future layers to which the neuron is connected and the process is repeated. ultimately a value is produced for the outputs of the neurons in the output layer. thus each neuron performs 1 where tii are continuous valued positive or negative weights 9. is a constant and gx is a nonlinear function that is often chosen to be of a sigmoidal form. for example one may choose 1 gz 2 1 tanhz 2 where tanh is the hyperbolic tangent although the exact formula of the sigmoid is irrelevant to the results. if t are the target output values for the pth input pattern then ones trains the network by minimizing e l l tp op 2 p i 3 where tp is the target output values taken from the training set and opl is the output of the network when the pth input pattern of the training set is presented on the input layer. i indexes the number of neurons in the output layer. an iterative procedure is used to minimize s. for example the commonly used steepest descents procedure is implemented by changing tii and s by ati and as where t. .. e 1 ae at. .. 1 445 4a 4b this implies that e 0 and hence e will decrease to a local minimum. use o the chain .rule and definition of some intermediate quantities allows the followmg expressions for tij to be obtained rumelhart 1987 tij l e6lpo.p p where if i is labeling a neuron in the output layer and 6jp op 1 op» lti j 6p j sa sb 6 7 if i labels a neuron in the hidden layers. therefore one computes 6jp for the output layer first then uses eqn. 7 to computer 6i p for the hidden layers and finally uses eqn. s to make an adjustment to the weights. we remark that the steepest descents procedure in common use is extremely slow in simulation and that a better minimization procedure such as the classic conjugate gradient procedure w. press 1986 can offer quite significant speedups. many applicid173 cations use bit representations 01 for symbols and attempt to have a neural net learn fundamental relationships between the symbols. this procedure has been successfully used in converting text to speech t. sejnowski 1986 and in determining whether a given fragment of dna codes for a protein or not a. lapedes r. farber 1987. there is no fundamental reason however to use integers as values for input and output. if the inputs and outputs are instead a collection of floating point numbers then the network after training yields a specific continuous function in n variables for n inputs involving gx le. hyperbolic tanhs that provides a type of nonlinear least mean square interpolant formula for the discrete set of data points in the training set. use of this formula a 111 1 ... 11 when given a new input not in the training set is then either interpolation or extrapolation. since the output values when assumed to be floating point numbers may have a dynamic range great than 101 one may modify the gx on the output layer to be a linear function instead of sigmoidal so as to encompass the larger dynamic range. dynamic range of the input values is not so critical however we have found that numerical problems may be avoided by scaling the inputs and 446 also the outputs to 01 training the network and then rescaling the ti j to encompass the original dynamic range. the point is that scale changes in i and 0 may for feedforward networks always be absorbed in the t ijj j and vice versa. we use this procedure backpropagation conjugate gradient linear outputs and scaling in the following section to predict points in a chaotic time series. 3. prediction let us consider situations in nature where a system is described by nonlincid173 ear differential equations. this is faily generic. we choose a particular nonlinear equation that has an infinite dimensional phase space so that it is similar to other infinite dimensional systems such as partial differential equations. a differcid173 ential equation with an infinite dimensional phase space i.e. an infinite number of values are necessary to describe the initial condition is a delay differential equation. we choose to consider the time series generated by the glassmackey equation x azt 1 1 z 10 t 1 b t z 8 this is a nonlinear differential delay equation with an initial condition specified by an initial function defined over a strip of width l hence the infinite dicid173 mensional phase space i.e. initial functions not initial constants are required. choosing this function to be a constant function and a .2 b .1 and l 17 yields a time series xt obtained by integrating eqn. 8 that is chaotic with a fractal attractor of dimension 2.1. increasing l to 30 yields more complicated evolution and a fractal dimension of 3.5. the time series for 500 time steps for 130 time in units of 1 is plotted in figure 2. the nonlinear evolution of the system collapses the infinite dimensional phase space down to a low approxicid173 mately 2 or 3 dimensional fractal attracting set. similar chaotic systems are not uncommon in nature. figure 2. example time series at tau 30. 447 the goal is to take a set of values of xo at discrete times in some time window containing times less than t and use the values to accurately predict xt p where p is some prediction time step into the future. one may fix p collect statistics on accuracy for many prediction times t by sliding the window along the time series and then increase p and again collect statistics on accuracy. this one may observe how an average index of accuracy changes as p is increased. in terms of figure 2 we will select various prediction time steps p that correspond to attempting to predict within a bump to predicting a couple of bumps ahead. the fundamental nature of chaos dictates that prediction accuracy will decrease as p is increased. this is due to inescapable inaccuracies of finite precision in specifying the x t at discrete times in the past that are used for predicting the future. thus all predictive methods will degrade as p is increased the question is how rapidly does the error increase with p we will demonstrate that the neural net method can be orders of magnitude more accurate than conventional methods at large prediction time steps p. our goal is to use backpropagation and a neural net to construct a function ot p f 11t 12t a ... lmt ma 9 where ot p is the output of a single neuron in the output layer and 11 1m are input neurons that take on values zt zt a ... zt rna where a is a time delay. ot p takes on the value xt p. we chose the network configuation of figure 1. we construct a training set by selecting a set of input values 10 1m xt p rna with associated output values 0 xtp p for a collection of discrete times that are labelled by tp. typically we used 500 io pairs in the training set so that p ranged from 1 500. thus we have a collection of 500 sets of lip lp ... 1 op to use in training the neural net. this procedure of using delayed sampled values of xt can be implemented by using tapped decid173 lay lines just as is normally done in linear signal processing applications b. widrow 1985. our prediction procedure is a straightforward nonlinear extencid173 sion of the linear widrow hoff algorithm. after training is completed prediction is performed on a new set of times t p not in the training set i.e. for p 500. we have not yet specified what m or a should be nor given any indication why a formula like eqn. 9 should work at all. an important theorem of takens takens 1981 states that for flows evolving to compact attracting manifolds of dimension d.a that a functional relation like eqn. 9 does exist and that m lies in the range d.a m 1 2d.a 1. we therefore choose m 4 for t 30. takens provides no information on a and we chose a 6 for both cases. we found that a few different choices of m and a can affect accuracy by a factor of 2 a somewhat significant but not overwhelming sensitivity in view of the fact that neural nets tend to be orders of magnitude more accurate than other methods. takens theorem gives no information on the form of fo in eqn. 9. it therefore 448 is necessary to show that neural nets provide a robust approximating procedure for continuous fo which we do in the following section. it is interesting to note that attempts to predict future values of a time series using past values of xt from a tapped delay line is a common procedure in signal processing and yet there is little if any reference to results of nonlinear dynamical systems theory showing why any such attempt is reasonable. after trainin the neural net as described above we used it to predict 500 new values of xtj in the future and computed the average accuracy for these points. the accuracy is defined to be the average root mean square error divided by a constant scale factor which we took to be the standard deviation of the data. it is necessary to remove the scale dependence of the data and dividing by the standard deviation of the data provides a scale to use. thus the resulting index of accuracy is insensitive to the dynamic range of x t. as just described if one wanted to use a neural net to continuously predict xt values at say 6 time steps past the last observed value i.e. wanted to construct a net predicting x t 6 then one would train one network at p 6 to do this. if one wanted to always predict 12 time steps past the last observed x t then a separate p 12 net would have to be trained. we in fact trained separate networks for p ranging between 6 and 100 in steps of 6. the index of accuracy for these networks as obtained by computing the index of accuracy in the prediction phase is plotted as curve d in figure 3. there is however an alternate way to predict. if one wished to predict say xt 12 using a p 6 net then one can iterate the p 6 net. that is one uses the p 6 net to predict the xt 6 values and then feeds xt 6 back into the input line to predict xt 12 using the predicted xt 6 value instead of the observed xt 6 value. in fact one cant use the observed xt 6 value because it hasnt been observed yet the rule of the game is to use only data occurring at time t and before to predict x t 12. this procedure corresponds to iterating the map given by eqn. 9 to perform prediction at multiples of p. of course the delays must be chosen commensurate with p. this iterative method of prediction has potential dangers. because in our example of iterating the p 6 map the predicted xt 6 is always made with some error then this error is compounded in iteration because predicted and not observed values are used on the input lines. however one may precid173 dict more accurately for smaller p so it may be the case that choosing a very accurate small p prediction and iterating can ultimately achieve higher accucid173 racy at the larger ps of interest. this turns out to be true and the iterated net method is plotted as curve e in figure 3. it is the best procedure to use. curves abc are alternative methods iterated polynomial widrowhoff and noniterated polynomial respectively. more information on these conventional methods is in lapedes and farber 1987 . b d 449 e a c 1 i i j i f i . . i i .. i i i i i i i i i i i i i i i p1ictlon . p t.u3 30 400 figure 3. 1 .8 .6 .4 .2 o o 4. why it works consider writing out explicitly eqn. 9 for a two hidden layer network where the output is assumed to be a linear neuron. we consider input connects to hidden layer 1 hidden layer 1 to hidden layer 2 and hidden layer 2 to output therefore recall that the output neurons a linear computing element so that only two gos occur in formula 11 due to the two nonlinear hidden layers. for ease in later analysis let us rewrite this formula as ot l ttjcg su mle ole ot ie th 2 where 12a 12b 450 the ts and ps are specific numbers specified by the training algorithm so that after training is finished one has a relatively complicated formula 12a 12b that expresses the output value as a specific known function of the input values ot 1117 12 .lm. a functional relation of this form when there is only one output may be viewed as surface in m 1 dimensional space in exactly the same manner one interprets the formula z fxy as a two dimensional surface in three dimensional space. the general structure of fo as determined by eqn. 12a 12b is in fact quite simple. from eqn. 12b we see that one first forms a sum of go functions where go is s sigmoidal function and then from eqn. 12a one orms yet another sum involving go functions. it may at first be thought that this special simple form of fo restricts the type of surface that may be represented by ot fii this initial tl.ought is wrong the special form of eqn. 12 is actually a general representation for quite arbitrary surfaces. to prove that eqn. 12 is a reasonable representation for surfaces we first point out that surfaces may be approximated by adding up a series of bumps that are appropriately placed. an example of this occurs in familiar fourier analysis where wave trains of suitable frequency and amplitude are added together to approximate curves or surfaces. each half period of each wave of fixed wavelength is a bump and one adds all the bumps together to form the approximant. let us now see how eqn. 12 may be interpreted as adding together bumps of specified heights and positions. first consider sumk which is a sum of g functions. in figure 4 we plot an example of such a go function for the case of two inputs. figure 4. a sigmoidal surface. 451 the orientation of this sigmoidal surface is determined by t sit the position by 81 and height by ti. now consider another go function that occurs in sum. the 8 of the second go function is chosen to displace it from the first the tii is chosen so that it has the same orientation as the first and t i is chosen to have opposite sign to the first. these two g functions occur in sum and so to determine their contribution to sum we sum them together and plot the result in fi ure 5. the result is a ridged surface. figure 5. a ridge. since our goal is to obtain localized bumps we select another pair of go functions in sumk add them together to get a ridged surface perpendicular to the first ridged surface and then add the two perpendicular ridged surfaces together to see the contribution to sumk. the result is plotted in figure 6. figure 6. a pseudobump . 452 we see that this almost worked in so much as one obtains a local maxima by this procedure. however there are also saddlelike configurations at the corners which corrupt the bump we were trying to obtain. note that one way to fix this is to take gsumk ok which will if ole is chosen appropriately depress the local minima and saddles to zero while simultaneously sending the central maximum towards 1. the result is plotted in figure 7 and is the sought after b figure 7. a bump. furthermore note that the necessary go function is supplied by eqn. 12. therefore eqn. 12 is a procedure to obtain localized bumps of arbitrary height and position. for two inputs the kth bump is obtained by using four go funccid173 tions from sumk two go functions for each ridged surface and two ridged surfaces per bump and then taking go of the result in eqn. 12a. the height of the kth bump is determined by t tje in eqn. 12a and the k bumps are added together by that equation as well. the general network architecture which corcid173 responds to the above procedure of adding two go functions together to form a ridge two perpendicular ridges together to form a pseudobump and the final go to form the final bump is represented in figure 8. to obtain any number ot bumps one adds more neurons to the hidden layers by repeatedly using the connectivity of figure 8 as a template le. four neurons per bump in hidden layer 1 and one neuron per bump in hiclden layer 2. 453 figure 8. connectivity needed to obtain one bump. add four more neurons to hidden layer 1 and one more neuron to hidden layer 2 for each additional bump. one never needs more than two layers or any other type of connectivity than that already schematically specified by figure 8. the accuracy of the approximation depends on the number of bumps which in turn is specified by the number of neurons per layer. this result is easily generalized to higher dimensions more than two inputs where one needs 2m hiddens in the first hidden layer and one hidden neuron in the second layer for each bump. the argument given above also extends to the situation where one is procid173 cessing symbolic information with a neural net. in this situation the input information is coded into bits say os and is and similarly for the output. or the inputs may still be real valued numbers in which case the binary output is attempting to group the real valued inputs into separate classes. to make the output values tend toward 0 and lone takes a third and final go on the output layer i.e. each output neuron is represented by got where ot is given in eqn. 11 . recall that up until now we have used hnear neurons on the output layer. in typical backpropagation examples one never actually achieves a hard 0 or 1 on the output layers but achieves instead some value between 0.0 and 1.0. then typically any value over 0.5 is called 1 and values under 0.5 are called o. this postprocessing step is not really outside the framework of the network formalism because it may be performed by merely increasing the slope of the sigmoidal function on the output layer. therefore the only effect of the third and final go function used on the output layer in symbolic information processing is to pass a hyperplane through the surface we have just been discid173 cussing. this plane cuts the surface forming decision regions in which high values are called 1 and low values are called o. thus we see that the heart of the problem is to be able to form surfaces in a general manner which is then cut by a hyperplane into general decision regions. we are therefore able to conclude that the network architecture consisting of just two hidden layers is sufficient for learning any symbol processing training set. for boolean symbol mappings one need not use the second hidden layer to remove the saddles on the bump c.f. fig. 6. the saddles are lower than the central maximum so one may choose a threshold on the output layer to cut the bump at a point over the saddles to yield the correct decision region. whether this representation is a reasonable one for subsequently achieving good prediction on a prediction set as opposed to memorizing a training set is an issue that we address below. 454 we also note that use of sigma iii units rummelhart 1986 or high order correlation nets y.c. lee 1987 is an attempt to construct a surface by a general polynomial expansion which is then cut by a hyperplane into decision regions as in the above. therefore the essential element of all these neural net learning algorithms are identical le. surface construction only the particular method of parameterizing the surface varies from one algorithm to another. this geometrical viewpoint which provides a unifying framework for many neural net algorithms may provide a useful framework in which to attempt construction of new algorithms. adding together bumps to approximate surfaces is a reasonable procedure to use when dealing with real valued inputs. it ties in to general approximation theory c.f. fourier series or better yet b splines and can be quite successful as we have seen. clearly some economy is gained by giving the neural net bumps to start with instead of having the neural net form its own bumps from sigmoids. one way to do this would be to use multidimensional gaussian functions with adjustable parameters. the situation is somewhat different when processing symbolic binary valcid173 ued data. when input symbols are encoded into n bit bitstrings then one has well defined input values in an n dimensional input space. as shown above one can learn the training set of input patterns by appropriately forming and placing bump surfaces over this space. this is an effective method for memorizing the training set but a very poor method for obtaining correct predictions on new input data. the point is that in contrast to real valued inputs that come from say a chaotic time series the input points in symbolic processing problems are widely separated and the bumps do not add together to form smooth surfaces. furthermore each input bit string is a corner of an 2n vertex hypercube and there is no sense in which one corner of a hypercube is surrounded by the other corners. thus the commonly used input representation for symbolic processing problems requires that the neural net extrapolate the surface to make a new prediction for a new input pattern i.e. new corner of the hypercube and not interpolate as is commonly the case for real valued inputs. extrapolation is a farmore dangerous procedure than interpolation and in view of the separated bumps of the training set one might expect on the basis of this argument that neural nets would fail dismally at symbol processing. this is not the case. the solution to this apparent conundrum of course is that although it is sufficient for a neural net to learn a symbol processing training set by forming bumps it is not necessary for it to operate in this manner. the simplest examcid173 ple of this occurs in the xor problem. one can implement the inputoutput mapping for this problem by duplicating the hidden layer architecture of figure 8 appropiately for two bumps i.e. 8 hid dens in layer 1 2 hid dens in layer 2. as discussed above for boolean mappings one can even eliminate the second hidden layer. however the architecture of figure 9 will also suffice. figure 9. connectivity for xor output hidden input 455 plotting the output of this network figure9 as a function of the two inputs yields a ridge orientated to run between 01 and 10 figurelo. thus a neural net may learn a symbolic training set without using bumps and a high dimensional version of this process takes place in more complex symbol procid173 cessing tasks.ridgeravine representations of the training data are considerably more efficient than bumps less hidden neurons and weights and the extended nature of the surface allows reasonable predictions i.e. extrapolations. figure 10 xor surface 1 1 5. conclusion. neural nets in contrast to popular misconception are capable of quite accurate number crunching with an accuracy for the prediction problem we considered that exceeds conventional methods by orders of magnitude. neural nets work by constructing surfaces in a high dimensional space and their opercid173 ation when performing signal processing tasks on real valued inputs is closely related to standard methods of functional pproximation. one does not need more than two hidden layers for processing real valued input data and the accid173 curacy of the approximation is controlled by the number of neurons per layer and not the number of layers. we emphasize that although two layers of hidden neurons are sufficient they may not be efficient. multilayer architectures may provide very efficient networks in the sense of number of neurons and number of weights that can perform accurately and with minimal cost. effective prediction for symbolic input data is achieved by a slightly differcid173 ent method than that used for real value inputs. instead of forming localized bumps which would accurately represent the training data but would not precid173 dict well on new inputs the network can use ridgeravine like surfaces and generalizations thereof to efficiently represent the scattered input data. while neural nets generally perform prediction by interpolation for real valued data they must perform extrapolation for symbolic data if the usual bit representacid173 tions are used. an outstanding problem is why do tanh representations seem to extrapolate well in symbol processing problema how do other functional bases do how does the representation for symbolic inputs affect the ability to extra olate this geometrical viewpoint provides a unifyimt framework for examimr 456 many neural net algorithms for suggesting questions about neural net operation and for relating current neural net approaches to conventional methods. acknowledgment. we thank y. c. lee j. d. farmer and j. sidorovich for a number of valuable discussions. references c. barnes c. burks r. farber a. lapedes k. sirotkin pattern recognition by neural nets in genetic databases manuscript in preparation j. denker et. al. automatic learning rule extractionand generalization att bell laboratories preprint 1987 d. farmer j.sidorowich phys.rev. lett. 598 p. 8451987 h. haken phys. lett. a53 p77 1975 a. lapedes r. farber nonlinear signal processing using neural networks prediction and system modelling laur8726621987 y.c. lee physica 22d1986 r. lippman ieee asap magazinep.4 1987 d. ruelle f. takens comm. math. phys. 20 p167 1971 d. rummelhart j. mcclelland in parallel distributed processing vol. 1 m.i.t. press cambridge ma 1986 d. russel et al. phys. rev. lett. 45 pu75 1980 t. sejnowski et al. net talk a parallel network that learns to read aloud johns hopkins univ. preprint 1986 h. swinney et al. physics today 31 8 p41 1978 f. takens detecting strange attractor in turbulence lecture notes in mathcid173 ematics d. rand l. young editors springer berlin p366 1981 k. tomita et ai. j. stat. phys. 21 p65 1979 '"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-_MGG4fGJ8U"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIfPRz0BYFsK"
      },
      "source": [
        "## LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "D9PpTD8BGJ_F",
        "outputId": "a09b41bb-5cf2-4190-dcea-6c7a6a44fccc"
      },
      "source": [
        "from gensim.corpora import Dictionary\n",
        "\n",
        "texts = papers_df['full_text_clean']\n",
        "\n",
        "dictionary = Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "import numpy\n",
        "numpy.random.seed(1) # setting random seed to get the same results each time.\n",
        "\n",
        "from gensim.models import ldamodel\n",
        "model = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=10, minimum_probability=1e-8)\n",
        "model.show_topics()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-66c3d61c2415>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpapers_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_text_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprune_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, documents, prune_at)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;31m# update Dictionary with the document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ignore the result, here we only care about updating token ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         logger.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/corpora/dictionary.py\u001b[0m in \u001b[0;36mdoc2bow\u001b[0;34m(self, document, allow_update, return_missing)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \"\"\"\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"doc2bow expects an array of unicode tokens on input, not a single string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# Construct (word, frequency) mapping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: doc2bow expects an array of unicode tokens on input, not a single string"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p76cfXTIGKCV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_TBeOqaj9ZO"
      },
      "source": [
        "## Another Way to LDA \n",
        "How do you feel about this rime?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6wKcrg-GKE3",
        "outputId": "a8ece894-66cb-4e4d-e3c0-af178276a035"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(max_df=0.9, min_df=2, stop_words='english', token_pattern=r'(?u)\\b[A-Za-z]+\\b')\n",
        "papers_tf_idf = tfidf.fit_transform(papers_df['full_text_clean'])\n",
        "\n",
        "papers_tf_idf"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<9677x122023 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 8250043 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmSlpcvdGKJr",
        "outputId": "789cd161-11b2-4386-f9e1-2152c7df8ec8"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "LDA = LatentDirichletAllocation(n_components=15, random_state=101)\n",
        "\n",
        "# This can take a while, we are dealing with large number of documents here\n",
        "LDA.fit(papers_tf_idf)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
              "                          evaluate_every=-1, learning_decay=0.7,\n",
              "                          learning_method='batch', learning_offset=10.0,\n",
              "                          max_doc_update_iter=100, max_iter=10,\n",
              "                          mean_change_tol=0.001, n_components=15, n_jobs=None,\n",
              "                          perp_tol=0.1, random_state=101, topic_word_prior=None,\n",
              "                          total_samples=1000000.0, verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4F_Dj9kk75P",
        "outputId": "aecd1e7a-4e22-4c00-b9ee-630aefa5f238"
      },
      "source": [
        "# What topics did we get?\n",
        "\n",
        "for index, topic in enumerate(LDA.components_):\n",
        "    print(f\"THE TOP 15 WORDS FOR TOPIC #{index}\")\n",
        "    list_keywords = [tfidf.get_feature_names()[index] for index in topic.argsort()[-10:]]\n",
        "    print(list_keywords)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THE TOP 15 WORDS FOR TOPIC #0\n",
            "['kary', 'pcn', 'gpn', 'spore', 'ifo', 'epca', 'uoi', 'fascicles', 'qrouting', 'zsl']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #1\n",
            "['cann', 'sagald', 'pbil', 'endmembers', 'ifat', 'ihmm', 'bicluster', 'dpsgd', 'sgr', 'sbp']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #2\n",
            "['lpa', 'pux', 'tensorsketch', 'sonn', 'bisimulation', 'ebnn', 'idc', 'nofm', 'dvae', 'cvar']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #3\n",
            "['disaggregation', 'bidder', 'buyers', 'revenue', 'gpr', 'auction', 'auctions', 'coalescent', 'sghmc', 'seller']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #4\n",
            "['forgeries', 'houdini', 'vamp', 'hca', 'qbc', 'gpomdp', 'bbvi', 'ggp', 'rivalry', 'foba']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #5\n",
            "['multibatch', 'asvm', 'wnll', 'pcsa', 'strf', 'twf', 'nettrim', 'kanji', 'nsm', 'mwis']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #6\n",
            "['tlasso', 'hnn', 'parsec', 'icn', 'hots', 'shareboost', 'coda', 'metaclass', 'rgd', 'ksupport']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #7\n",
            "['avgm', 'dpca', 'hyperq', 'sco', 'ktf', 'nao', 'rsnns', 'ydox', 'dcnns', 'lta']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #8\n",
            "['gista', 'taskonomy', 'dstump', 'lsem', 'dataflow', 'ddag', 'oam', 'trbm', 'larstd', 'glas']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #9\n",
            "['romma', 'diabolo', 'qos', 'vcl', 'ssda', 'gbn', 'partigame', 'universum', 'capsules', 'capsule']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #10\n",
            "['silp', 'cnaps', 'rff', 'hyperalignment', 'tms', 'pflds', 'ctw', 'plasma', 'adahedge', 'raam']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #11\n",
            "['svc', 'polytree', 'plv', 'lsir', 'pxly', 'muddy', 'mmap', 'knockoff', 'reactants', 'plr']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #12\n",
            "['dogleg', 'sconcave', 'sgns', 'edml', 'sppca', 'spikernel', 'vrm', 'semvr', 'elicitable', 'dfa']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #13\n",
            "['matrix', 'neural', 'training', 'network', 'y', 'f', 'algorithm', 'data', 'model', 'x']\n",
            "\n",
            "\n",
            "THE TOP 15 WORDS FOR TOPIC #14\n",
            "['mediator', 'fisherface', 'linskers', 'ddcrp', 'legislation', 'gpssm', 'empowerment', 'gpfa', 'kfd', 'mre']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFsgv6SQdzhH"
      },
      "source": [
        "### Drawing a Heatmap of the world with colors based on amounts of publications per country.\n",
        "\n",
        "For that I will need to know the location of the authors of each paper. I can either draw that from each paper (in the end of the authors' list appears the institution and its address), I can extract the location using Spacy or another method. OR I can get each institution from the writers' list, fetch its address via Google API and merge it with the papers table to find amounts per country and then plot it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgbQAvAfqSU4"
      },
      "source": [
        "# Checking if I can fetch the institution's location using Spacy. Then I can plot a heat map of the world with number of publication per each location,\n",
        "# I'm also curious to see how many publishers are from outside the U.S and Europe.\n",
        "\n",
        "import spacy\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()\n",
        "\n",
        "gpe = [] # countries, cities, states\n",
        "loc = [] # non gpe locations, mountain ranges, bodies of water\n",
        "\n",
        "city1 = []\n",
        "country1 = []\n",
        "\n",
        "for i in range(10):\n",
        "  gpe = []\n",
        "  doc = nlp(papers_df['full_text'][i])\n",
        "  for ent in doc.ents:\n",
        "      if (ent.label_ == 'GPE'):\n",
        "          gpe.append(ent.text)\n",
        "  print('---------- Iteration Number ',i)\n",
        "  print(gpe)\n",
        "  city1.append(gpe[0])\n",
        "  country1.append(gpe[1])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LvQUtdkU6cr-",
        "outputId": "4b056402-8a80-45a7-9f91-75185d2547af"
      },
      "source": [
        "i = 7\n",
        "papers_df['full_text'][i]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'554 \\n\\nSTABILITY RESULTS  FOR NEURAL  NETWORKS \\n\\nA.  N.  Michell, J. A.  FarreUi  , and W.  Porod2 \\n\\nDepartment of Electrical and  Computer Engineering \\n\\nUniversity of Notre  Dame \\n\\nNotre Dame, IN 46556 \\n\\nABSTRACT \\n\\nIn the present paper we survey and utilize results from the qualitative theory of large \\nscale interconnected dynamical systems in order to develop  a  qualitative theory for  the \\nHopfield model of neural networks.  In our approach we  view such networks as  an inter(cid:173)\\nconnection of many single neurons.  Our results  are  phrased in  terms of the  qualitative \\nproperties of the individual neurons and in terms of the properties of the interconnecting \\nstructure of the neural  networks.  Aspects of neural networks which  we  address include \\nasymptotic stability,  exponential stability,  and instability  of an  equilibrium;  estimates \\nof trajectory bounds; estimates of the domain of attraction of an asymptotically stable \\nequilibrium;  and stability of neural networks  under structural perturbations. \\n\\nINTRODUCTION \\n\\nIn recent years, neural networks have attracted considerable attention as  candidates \\nfor  novel  computational systemsl- 3 .  These  types  of large-scale  dynamical  systems,  in \\nanalogy  to  biological  structures,  take  advantage  of distributed  information  processing \\nand  their  inherent  potential  for  parallel  computation4,5.  Clearly,  the  design  of such \\nneural-network-based  computational  systems  entails  a  detailed  understanding  of  the \\ndynamics  of large-scale  dynamical  systems.  In particular,  the stability  and instability \\nproperties  of the  various  equilibrium  points  in  such  networks  are  of interest,  as  well \\nas  the extent of associated  domains of attraction  (basins  of attraction)  and  trajectory \\nbounds. \\n\\nIn the present paper, we apply and survey results from the qualitative theory oflarge \\nscale  interconnected  dynamical systems6 - 9  in order to  develop  a  qualitative theory for \\nneural  networks.  We  will  concentrate here  on  the  popular  Hopfield  model3 ,  however, \\nthis type of analysis may also be applied to other models.  In particular, we  will  address \\nthe  following  problems:  (i)  determine  the  stability  properties  of a  given  equilibrium \\npoint;  (ii)  given  that a  specific equilibrium point of a  neural network is  asymptotically \\nstable, establish an estimate for its domain of attraction; (iii) given a set of initial condi(cid:173)\\ntions  and external inputs, establish estimates for  corresponding trajectory bounds;  (iv) \\ngive  conditions for  the instability of a  given equilibrium  point;  (v)  investigate  stability \\nproperties under structural perturbations.  The present  paper contains local  results.  A \\nmore detailed treatment of local stability results can be found in Ref.  10, whereas global \\nresults  are contained in Ref.  1l. \\n\\nIn arriving at the results of the present paper,  we  make use  of the method of anal(cid:173)\\n\\nysis  advanced  in  Ref.  6.  Specifically,  we  view  high  dimensional neural  network  as  an \\n\\nIThe work of A.  N.  Michel  and  J.  A.  Farrell was supported by  NSF  under grant  ECS84-19918. \\n2The work of W.  Porod was supported by  ONR under grant  NOOOI4-86-K-0506. \\n\\n© American Institute of Physics 1988 \\n\\n\\x0c555 \\n\\ninterconnection of individual subsystems  (neurons).  This  interconnected systems  view(cid:173)\\npoint makes  our  results  distinct  from  others  derived  in  the literature1,12.  Our  results \\nare  phrased  in  terms  of  the  qualitative  properties  of the  free  subsystems  (individual \\nneurons, disconnected from the network) and in terms of the properties of the intercon(cid:173)\\nnecting  structure  of the  neural  network.  As  such,  these  results  may  constitute  useful \\ndesign tools.  This approach makes  possible the systematic analysis of high dimensional \\ncomplex systems and it frequently enables one  to circumvent difficulties encountered in \\nthe analysis of such systems  by conventional methods. \\n\\nThe  structure  of this  paper  is  as  follows.  We  start  out  by  defining  the  Hopfield \\nmodel  and  we  then introduce  the interconnected systems  viewpoint.  We  then  present \\nrepresentative stability results, including estimates of trajectory bounds and of domains \\nof attraction, results for instability, and conditions for stability under structural pertur(cid:173)\\nbations.  Finally, we  present concluding remarks. \\n\\nTHE HOPFIELD  MODEL  FOR NEURAL  NETWORKS \\n\\nIn the present paper we consider neural networks of the Hopfield type3 •  Such systems \\n\\ncan be represented by  equations of the form \\n\\nUi  = ..... biUi + I:Aij Gj(Uj) + Ui(t),  for  i  = 1, ... ,N, \\n\\nN \\n\\n(1) \\n\\nj=1 \\n\\nwhere  Aij  = *\"Ui(t) = l~g)  and  bi  = *..  As  usual,  Ci  >  O,Tij \\ni:;,RijfR  = \\n(-00,00),\\':.  =  ~ +E.f=IITiil,  Ri  >  O,Ii:  R+  = [0,00)  ~ R,Ii  is  continuous, \\nUi  =  ~,Gi :  R  ~ (-1,1), Gi  is  continuously  differentiable  and  strictly  monotoni(cid:173)\\ncally increasing (Le.,  Gi( uD  > Gi( u~\\') if and only if u~ > u~\\'), UiGi( Ui)  > 0 for all Ui  ::j;  0, \\nand Gi(O)  =  O.  In (1), C i  denotes  capacitance,  Rij  denotes  resistance  (possibly includ(cid:173)\\ning a sign inversion due to an inverter), Gi (·) denotes an amplifier nonlinearity, and Ii(\\') \\ndenotes an external input. \\n\\nIn  the  literature it is  frequently  assumed  that  Tij  =  Tji  for  all  i,j =  1, ... , N  and \\nthat Tii  =  0 for  all  i  =  1, ... , N.  We  will  make  these assumptions only when explicitly \\nstated. \\n\\nWe  are  interested  in  the  qualitative  behavior  of solutions  of (1)  near  equilibrium \\npoints  (rest  positions  where  Ui  ==  0,  for i  =  1, ... , N).  By  setting the external inputs \\nUi(t),  i = 1, ... , N, equal to zero, we  define U*  =  [ui, ... , u\"NV fRN  to be an equilibrium \\nfor  (1)  provided  that  -biui\\' + E.f=l Aij  Gj(uj) = 0, \\nfor  i  = 1, ... ,N. The locations \\nof such  equilibria in  RN  are  determined  by  the  interconnection  pattern of the  neural \\nnetwork (i.e., by the parameters Aij, i,j =  1,. \", N) as  well as by the parameters bi  and \\nthe nature of the nonlinearities  Gi(\\')\\' i  = 1, ... ,N. \\n\\nThroughout, we  will  assume that a given equilibrium u*  being analyzed is  an isolated \\nequilibrium for  (1), i.e., there exists an r  > 0 such that in the neighborhood  B( u*, r) = \\n{( u  - u*)fRN  : lu - u*1  < r}  no equilibrium for  (1), other than u  =  u*, exists. \\n\\nWhen analyzing the stability properties of a given equilibrium point, we  will be able \\nto assume, without loss of generality, that this equilibrium is located at the origin u  =  0 \\nof RN.  If this is not the case, a  trivial transformation can be employed which  shifts the \\nequilibrium point  to the origin and which  leaves  the structure of (1)  the same. \\n\\n\\x0c556 \\n\\nINTERCONNECTED SYSTEMS  VIEWPOINT \\n\\nWe  will  find  it convenient  to  view  system  (1)  as  an interconnection of N  free  sub(cid:173)\\n\\nsystems (or  isolated sUbsystems)  described  by equations of the form \\n\\nUnder this  viewpoint, the interconnecting structure of the system (1) is  given  by \\n\\nPi  =  -biPi + Aii Gi(Pi) + Ui(t). \\n\\nGi(Xb\"  . ,xn )  ~  L  AijGj(Xj),  i = 1, ... ,N. \\n\\nN \\n\\nj=1 \\nii:i \\n\\n(2) \\n\\n(3) \\n\\nFollowing  the  method  of analysis  advanced  in6 ,  we  will  establish  stability  results \\nwhich  are phrased in terms of the qualitative properties of the free  subsystems  (2)  and \\nin  terms  of the  properties  of the interconnecting  structure given  in  (3).  This  method \\nof analysis  makes  it  often  possible  to  circumvent  difficulties  that  arise  in the analysis \\nof complex  high-dimensional  systems.  Furthermore,  results  obtained  in  this  manner \\nfrequently  yield  insight into the dynamic behavior of systems in  terms of system  com-\\nponents and interconnections. \\n\\n. \\n\\nGENERAL STABILITY CONDITIONS \\n\\nWe  demonstrate below  an  example of a  result  for  exponential  stability  of an  equi(cid:173)\\n\\nlibrium  point.  The principal Lyapunov stability results for  such systems are presented, \\ne.g., in Chapter 5 of Ref.  7. \\n\\nWe  will  utilize the following  hypotheses in our first  result. \\n\\n(A-I)  For  system  (1), the external inputs are all zero, i.e., \\n\\nUi(t)  ==  0, \\n\\ni  =  1, ... , N. \\n\\n(A-2)  For system (1), the interconnections satisfy the estimate \\n\\nfor  all Ixil  < ri,  Ix;1  < rj,  i,j =  1, ... , N, where the ail  are real  constants. \\n\\n(A-3)  There exists an N-vector a> ° (i.e., aT =  (al, ... ,aN) and ai >  0, \\n\\n1, ... ,N) such that the  test  matrix S = [Sij] \\n\\nfor all  ~  = \\n\\nis  negative  definite,  where  the bi  are  defined  in (1)  and the  aij  are  given  in  (A-2). \\n\\n\\x0c557 \\n\\nWe  are  now in a  position to state and prove the following  result. \\n\\nTheorem 1  The equilibrium x = 0  of the  neural network (1)  is exponentially stable \\nif hypotheses  (A-l),  (A-2)  and  (A-3)  are  satisfied. \\n\\nProof.  For (1)  we  choose the  Lyanpunov function \\n\\nwhere  the  ai  are  given  in  (A-3).  This  function  is  clearly  positive  definite.  The  time \\nderi vati ve  of v  along the solutions of (1) is  given  by \\n\\n(4) \\n\\nDV(1)(X)  = 2: 2ai(2xd[-biXi + 2: Aij Gj(Xj)] \\n\\nN  1 \\n\\ni=1 \\n\\nwhere  (A-l) has been invoked.  In view of (A-2)  we  have \\n\\nN \\n\\nj=1 \\n\\nN \\n\\nj=1 \\n\\nDV(1)( x)  <  2: ai( -bix~ + Xi 2: aijX j) \\n\\nN \\n\\ni=1 \\n\\nwhere  r = mini(ri), IxI2 = (Ef:1 X~) 1/2, and  the matrix R =  [rij]  is  given  by \\n\\nfor  all IxI2  < r \\n\\nr;j = { ai( -bi + aii), \\n\\nai aij, \\n\\nt  = J \\ni ::J  j. \\n\\nBut it follows  that \\n\\nxT Rx =  xT ( R ~ RT)  X  =  xT Sx ::;  )w(S)  Ixl1 \\n\\n(5) \\n\\nwhere  S  is  the  matrix  given  in  (A-3)  and  AM(S)  denotes  the  largest  eigenvalue  of \\nthe  real  symmetric  matrix  S.  Since  S  is  by  assumption  negative  definite,  we  have \\nAM(S) < O.  It follows  from  (4)  and  (5)  that in some neighborhood of the origin x  =  0, \\nwe  have  c1lxl~  ~ v(x)  ~ c2lxl~  and  DV(1)(X)  ~ -c3Ixl~,  where  C1  =  ! mini ai  >  0, \\nC2  = ! maxi ai > 0, and C3  =  -AM(S) > O.  Hence,  the equilibrium  x  = ° of the neural \\n\\nnetwork  (1)  is  exponentially stable (c.f.  Theorem 9.10 in Ref.  7). \\n\\nConsistent  with  the  philosophy  of viewing  the  neural  network  (1)  as  an  intercon(cid:173)\\n\\nnection of N  free  subsystems  (2),  we  think  of the  Lyapunov function  (4)  as  consisting \\nof a  weighted sum of Lyapunov functions for  each free  subsystem  (2)  (with  Ui(t)  ==  0) . \\nThe  weighting  vector  a  >  0  provides  flexibility  to emphasize  the  relative  importance \\nof the qualitative  properties of the  various individual subsystems.  Hypothesis  (A - 2) \\nprovides  a  measure of interaction between  the various subsystems  (3).  Furthermore, it \\nis  emphasized  that  Theorem  1 does  not  require  that the parameters  Aij in  (1)  form  a \\nsymmetric matrix. \\n\\n\\x0c558 \\n\\nWEAK  COUPLING CONDITIONS \\n\\nThe test  matrix S given in hypothesis (A - 3) has off-diagonal terms which may be \\npositive  or  nonpositive.  For  the  special  case  where  the  off-diagonal  terms  of the  test \\nmatrix S =  [Sij]  are non-negative, equivalent stability results may be obtained which are \\nmuch easier to apply than Theorem  1.  Such results  are called  weak-coupling  conditions \\nin  the literature6,9.  The  conditions  8ij  ~ 0  for  all  i  ::J  j  may  reflect  properties  of the \\nsystem (1)  or they may be the consequence of a  majorization process. \\n\\nIn  the  proof of the  subsequent  result,  we  will  make  use  of some of the  properties \\nof M- matrices  (see,  for  example,  Chapter  2  in  Ref.  6).  In  addition  we  will  use  the \\nfollowing  assumptions. \\n\\n(A-4)  For system (1),  the nonlinearity Gi(Xi) satisfies  the sector condition \\n\\n(A-S)  The successive principal minors of the  N  X  N  test  matrix D  =  [dij ] \\n\\nare all positive where,  the bi  and Aij  are defined in (1)  and Ui2  is defined in (A - 4). \\nTheorem 2  The  equilibrium x  = 0  of the  neural network  (1)  is asymptotically sta(cid:173)\\nble  if hypotheses  (A-1),  (A-4)  and  (A-5)  are  true. \\n\\nProof.  The  proof proceeds10  along  lines  similar  to  the  one  for  Theorem  1,  this  time \\nwith the following  Lyapunov function \\n\\nN \\n\\nv(x) = L: Qilxd· \\n\\ni=l \\n\\n(6) \\n\\nThe above  Lyapunov function  again reflects  the interconnected nature of the whole \\nsystem.  Note  that  this  Lyapunov  function  may  be  viewed  as  a  generalized  Hamming \\ndistance of the state vector from  the origin. \\n\\nESTIMATES  OF TRAJECTORY BOUNDS \\n\\nIn  general,  one  is  not  only  interested  in  questions  concerning  the  stability  of  an \\n\\nequilibrium of the system  (1),  but also in performance.  One way  of assessing  the qual(cid:173)\\nitative  properties of the neural  system  (1)  is  by  investigating solution  bounds  near  an \\nequilibrium of interest.  We  present here  such a  result by assuming  that the hypotheses \\nof Theorem 2 are satisfied. \\n\\nIn the following,  we  will  not require  that the external inputs  Ui(t),  i  =  1, ... , N  be \\n\\nzero.  However, we  will need to make  the  additional assumptions enumerated below. \\n\\n\\x0c559 \\n\\n(A-6)  Assume that there exist  .xi  > 0,  for i  =  1, ... , N, and  an  (  > 0  such that \\n\\n(~~) IAjil  >  (  >  0, \\n\\ni  =  1, ... ,N \\n\\nN \\n\\nL: \\nj=1 \\ni:/;j \\n\\nwhere bi  and  Aij  are defined  in  (1)  and (Ti2  is  defined in (A-4). \\n\\n(A-7)  Assume that for  system  (1), \\n\\nN L: .xiIUi(t)1  ~ k  for  all \\n\\ni=l \\n\\nt ~ 0 \\n\\nfor  some constant  k  > 0  where the .xi,  i  = 1, ... , N  are defined  in  (A-6). \\n\\nIn  the  proof of our  next  theorem,  we  will  make  use  of a  comparison  result.  We \\nconsider  a  scalar comparison equation of the form  iJ  =  G(y)  where  y(R,G : B(r) - R \\nfor  some  r  > 0,  and G is continuous on B(r) =  {XfR: Ixl  < r}.  We  can  then prove the \\nfollowing  auxiliary  theorem:  Let  p(t)  denote  the  maximal  solution  of the  comparison \\nequation  with  p(to)  =  Yo(B(r), \\nt  ~ to  ~ 0  is  a  continuous \\nfunction  such  that  r(to)  $  Yo,  and  if  r(t)  satisfies  the  differential  inequality  Dr(t)  = \\nlimk-+O+  t sup[r(t + k)  - r(t)]  $  G(r(t))  almost  everywhere,  then  r(t)  $  p(t) for  t  ~ \\nto  ~ 0,  for  as  long  as  both  r(t)  and  p(t) exist.  For  the proof of this  result,  as  well  as \\nother comparison  theorems, see e.g.,  Refs.  6  and 7. \\n\\nt  ~ to  >  O.  If r(t), \\n\\nFor  the  next  theorem,  we  adopt  the  following  notation.  We  let  6  =  mini (Til \\nwhere  (Til  is  defined  in  (A  - 4),  we  let  c  =  (6  ,  where  (  is  given  in  (A-6),  and \\nwe  let  ¢(t,to,xo)  =  [¢I(t,to,xo)\\'\\'\\'\\',</>N(t,to,xo)]T  denote  the  solution  of  (1)  with \\n¢(to, to, xo)  =  Xo  =  (XlO,\"\"  xNol for some to  ~ O. \\n\\nWe  are  now  in a  position  to  prove  the following  result,  which  provides  bounds  for \\n\\nthe solution of(1). \\n\\nTheorem 3  Assume  that  hypotheses  (A-6)  and  (A-7)  are  satisfied.  Then \\n\\nk) \\n11¢(t, to, xo)11  =  L...\" .xil¢i(t, to, xo)  ::;  (a - - e-\\nC \\n\\ni=l \\n\\nc(t  t) \\n\\n- 0  + -,  t  ~ to  ~ 0 \\n\\nk \\nC \\n\\n~ ~ \\n\\nI \\n\\nprovided that a  > k/c and  IIxoll  =  E~l .xilxiOI  ~ a,  where  the  .xi,  i  =  1,. \", N  are \\n\\ngiven  in  (A-6)  and k  is given  in  (A-7). \\n\\nProof.  For (1)  we  choose the Lyapunov function \\n\\nN \\n\\nv(x) = L .xilxil· \\n\\ni=l \\n\\n(7) \\n\\n\\x0c560 \\n\\nAlong the  solutions of (1), we  obtain \\n\\nDV(l)(X)  ~ AT Dw + z: Ai!Ui(t)\\\\ \\n\\nN \\n\\ni=l \\n\\n(8) \\n\\nwhere  wT = [G1J;d\\\\Xl\\\\,\\'\\'\\'\\' G\\'Z~N)lxN\\\\]\\' A = (A}, ... ,ANf, and  D = [dij]  is  the test \\nmatrix  given  in  (A-5).  Note  that  when  (A-6)  is  satisfied,  as  in  the  present  theorem, \\ni = 1, ... , N) \\nthen  (A-5)  is  automatically satisfied.  Note also  that w  ~ 0  (Le.,  Wi  ~ 0, \\nand w  =  0 if and only if x = O. \\nUsing manipulations involving (A-6), (A-7) and (8), it is easy to show that DV(l)(X)  ~ \\n-cv(x) + k.  This ineqUality  yields  now  the  comparison equation  iJ  =  -cy + k,  whose \\nunique solution is  given  by \\n\\npet, to, Po)  =  (Po - ~) e-c(t-to) +~,  for all  t ~ to. \\n\\nH we  let  r  = v, then we  obtain from  the comparison result \\n\\npet)  ~ ret) =  v(4)(t,to,xo)) = 2: Ail4>i(t,to,xo)1  =  114>(t,to,xo)\\\\I, \\n\\nN \\n\\ni=l \\n\\ni.e.,  the desired  estimate is  true, provided  that  Ir(to)\\\\  = Ef:l Ai/XiOI  = IIxoll  ~ a  and \\na> kjc. \\n\\nESTIMATES  OF DOMAINS  OF ATTRACTION \\n\\nNeural  networks  of the  type  considered  herein  have  many  equilibrium  points.  If \\na  given  equilibrium  is  asymptotically  stable,  or exponentially  stable,  then  the  extent \\nof this  stability  is  of interest.  As  usual,  we  assume  that  x  =  0  is  the equilibrium  of \\ninterest.  If 4>(t, to, xo)  denotes a solution of the network (1)  with 4>(to, to, xo) = xo,  then \\nwe  would like  to know for  which  points Xo  it is  true that 4>( t, to, xo)  tends to the origin \\nas t  ---+  00.  The set of all such points Xo  makes up the domain of attraction (the basin  of \\nattraction)  of the equilibrium  x  =  O.  In general,  one  cannot  determine such  a  domain \\nin  its  entirety.  However,  several  techniques  have  been  devised  to estimate  subsets  of \\na  domain  of attraction.  We  apply  one  such  method  to  neural  networks,  making  use \\nof Theorem  1.  This  technique  is  applicable  to  our  other  results  as  well,  by  making \\nappropriate modifications. \\n\\nWe  assume that the hypotheses (A-I), (A-2) and (A-3) are satisfied and for  the free \\n\\nsubsystem  (2)  we  choose  the Lyapunov  function \\n\\n1  2 \\nVi(Pi)  = 2 Pi\\' \\n\\n(9) \\nThen  DVi(2) (Pi)  ~ (-bi + aii)p~,  \\\\Pi/  < ri  for  some  ri  > O.  If (A-3)  is  satisfied,  we \\n\\nmust have (-bi + aii) < 0 and DVi(2)(Pi)  is  negative definite over  B(ri). \\n\\nLet Gvo;  = {PifR : Vi(Pi)  = !p~ < trl ~ Voi}.  Then GVo ;  is  contained in the domain \\n\\nof attraction of the equilibrium Pi  =  0 for  the free  subsystem (2). \\n\\nTo  obtain  an  estimate  for  the  domain  of attraction of x  =  0 for  the  whole  neural \\n\\nnetwork  (1),  we  use the Lyapunov function \\n\\n\\x0cN  1 \\n\\nN \\n\\nv(x) - \\'\"\\' -\"\\'·x~ - \\'\"\\' o·v·(x·) \\n\\n-LJ2 ..... •• -LJ  • • • .  \\n\\n561 \\n\\n(10) \\n\\nIt is now  an  easy  matter to show that the set \\n\\ni=l \\n\\ni=l \\n\\nC>.  = {uRN: v(x) = LOiVi(Xi) < oX} \\n\\nN \\n\\ni=l \\n\\nwill  be  a  subset of the domain of attraction of x = 0 for  the neural network  (1), where \\n\\noX  =  min  (OiVOi)  =  min  (~Oir~) . \\n\\n1$.i$.N  2 \\n\\n• \\n\\nl$.i$.N \\n\\nIn  order  to obtain  the  best  estimate  of the  domain  of attraction  of x  = 0  by  the \\npresent method, we  must choose the 0i in an optimal fashion.  The reader is referred  to \\nthe literature9 ,l3,l4  where several  methods to accomplish  this are discussed. \\n\\nINSTABILITY  RESULTS \\n\\nSome  of the equilibrium  points  in  a  neural  network  may  be  unstable.  We  present \\nhere  a  sample instability  theorem  which  may  be  viewed  as  a  counterpart  to  Theorem \\n2.  Instability  results,  formulated  as  counterparts  to other stability  results  of the  type \\nconsidered herein  may  be obtained by making appropriate modifications. \\n\\n(A-B)  For system (1), the interconnections satisfy the estimates \\n\\nXiAiiGi(Xi)  <  OiAiiX;, \\n\\nIXiAjjGj(xj)1  $ \\n\\nIxdlAijlO\"j2l xil,  if; j \\n\\nwhere  OJ  = O\"il  when  Aii  < 0 and Oi  =  O\"i2  when  Aii  > 0 for  all  IXil  < ri,  and for \\nalllXjl < Tj,i,j = 1, ... ,N. \\n\\n(A-9)  The successive  principal minors of the N  x  N  test matrix D = [dij ] given by \\n\\nare  positive,  where  O\"i  =  ~ - Au  when  ifFIl  (i.e.,  stable subsystems)  and  O\"i \\n-!:; + Aji  when  ifFu  (i.e.,  unstable  subsystems)  with  F  = FII  U  Fu  and  F  = \\n{I, ., . , N} and Fu  f;  </>. \\n\\nWe  are now in a  position to prove the following  result. \\n\\nTheorem 4  The  equilibrium x  =  0  of the  neural network (1)  is unstable if hypotheses \\n(A-l),  (A-8)  and (A-g)  are  satisfied.  If in  addition,  FII  = </> \\n(</>  denotes  the  empty set), \\nthen  the  equilibrium  x  = 0  is completely unstable. \\n\\n\\x0c562 \\n\\nProof.  We choose the Lyapunov function \\n\\nifF .. \\n\\nifF. \\n\\nwhere ai  > 0,  i  =  1, ... ,N.  Along  the solutions of (1)  we  have  (following  the proof of \\nr  = miniri  where  aT =  (a}, ... ,aN), \\nTheorem  2),  DV(l)(X)  $  -aTDw for  all  x€B(r), \\n[ G1l;d IXll, ... , GNx~N) IXNI].  We  conclude  that \\nD  is  defined  in  (A-9),  and  wT  = \\nDV(l)(X)  is  negative  definite  over  B(r).  Since  every  neighborhood of the origin  x  = ° \\ncontains at least one point x\\' where v(x\\') < 0, it follows  that the equilibrium  x =  0 for \\n(1)  is  unstable.  Moreover,  when F, =  </>,  then the function  v(x) is  negative definite and \\nthe equilibrium  x  =  0 of (1) is in fact  completely unstable (c.f.  Chapter 5 in Ref.  7). \\n\\n(11) \\n\\nSTABILITY UNDER STRUCTURAL PERTURBATIONS \\n\\nIn specific applications involving adaptive schemes for  learning algorithms in neural \\nnetworks,  the  interconnection  patterns  (and  external  inputs)  are  changed  to  yield  an \\nevolution of different  sets  of desired  asymptotica.l1y  stable equilibrium  points  with  ap(cid:173)\\npropriate domains of attraction.  The present  diagonal dominance conditions  (see, e.g., \\nhypothesis  (A-6))  can  be  used  as  constraints  to guarantee  that  the  desired  equilibria \\nalways  have the desired  stability properties. \\n\\nTo be more specific, we assume that a given neural network has been designed with a \\nset of interconnections whose strengths can be varied from  zero to some specified values. \\nWe express  this  by writing in place of (1), \\n\\nXi  =  -biXi + L:8ij Aij Gj(Xj) + Ui(t), \\n\\nN \\n\\nj=l \\n\\nfor  i =  1, ... ,N, \\n\\n(12) \\n\\nwhere  0  $  8ij  $  1.  We  also  assume  that in  the given  neural network  things  have been \\narranged  in  such  a  manner  that  for  some  given  desired  value  ~ >  0,  it  is  true  that \\n~ =  mini (!:; - 8iiAii).  From  what  has  been  said  previously,  it should  now  be  clear \\nthat if Ui( t)  ==  0,  i = 1, ... ,N and if the diagonal  dominance conditions \\n\\n~ - t  (~~) 18ij Aiji  > 0,  for  i  =  1, ... ,N \\n\\n(13) \\n\\nj  = 1 \\ni:f;j \\n\\nare satisfied  for  some  Ai  > 0,  i  = 1, ... , N,  then the equilibrium  x  = ° for  (12)  will  be \\n\\nasymptotically stable.  It is important to recognize that condition (13) constitutes a sin(cid:173)\\ngle stability condition for  the neural network under structural perturbations.  Thus, the \\nstrengths of interconnections of the neural network  may  be rearranged in  any  manner \\nto achieve  some  desired  set  of equilibrium  points.  If (13)  is  satisfied,  then  these  equi(cid:173)\\nlibria will  be  asymptotically  stable.  (Stability under  structural perturbations is  nicely \\nsurveyed in Ref.  15.) \\n\\n\\x0c563 \\n\\nCONCLUDING  REMARKS \\n\\nIn  the  present  paper  we  surveyed  and  applied  results  from  the  qualitative  theory \\n\\nof large  scale  interconnected  dynamical  systems  in order to  develop  a  qualitative the(cid:173)\\nory  for  neural  networks  of the  Hopfield  type.  Our  results  are  local  and  use  as  much \\ninformation  as  possible  in  the  analysis  of a  given  eqUilibrium.  In  doing  so,  we  estab(cid:173)\\nlished  cri-teria  for  the  exponential  stability,  asymptotic  stability,  and instability  of an \\nequilibrium  in such  networks.  We  also  devised  methods  for  estimating the  domain  of \\nattraction of an  asymptotically stable equilibrium and for estimating trajectory bounds \\nfor  such  networks.  Furthermore,  we  showed  that  our  stability  results  are  applicable \\nto  systems  under  structural  perturbations  (e.g.,  as  experienced  in neural  networks  in \\nadaptive learning schemes). \\n\\nIn  arriving  at  the  above  results,  we  viewed  neural  networks  as  an  interconnection \\n\\nof many  single  neurons,  and we  phrased our results  in terms  of the qualitative proper(cid:173)\\nties  of the free  single  neurons  and  in  terms  of  the  network  interconnecting  structure. \\nThis viewpoint is  particularly well  suited for  the study of hierarchical structures which \\nnaturally lend themselves to implementations16  in VLSI.  Furthermore, this type of ap(cid:173)\\nproach  makes  it  possible  to  circumvent  difficulties  which  usually  arise  in  the  analysis \\nand synthesis of complex high  dimensional systems. \\n\\nREFERENCES \\n\\n[1]  For a review, see, Neural Networks for Computing, J. S. Denker, Editor, American \\n\\nInstitute of Physics Conference Proceedings 151, Snowbird,  Utah, 1986. \\n\\n[2]  J.  J. Hopfield and D.  W.  Tank,  Science 233, 625  (1986). \\n[3]  J.  J. Hopfield,  Proc.  Natl.  Acad.  Sci.  U.S.A.  79,2554 (1982),  and  ibid.  81,3088 \\n\\n(1984). \\n\\n[4]  G.  E. Hinton and J. A.  Anderson, Editors, Parallel Models  of Associative Memory, \\n\\nErlbaum,  1981. \\n\\n[5]  T. Kohonen,  Self-Organization  and Associative  Memory,  Springer-Verlag,  1984. \\n[6]  A.  N.  Michel  and  R.  K.  Miller,  Qualitative  Analysis  of Large  Scale  Dynamical \\n\\nSystems, Academic Press,  1977. \\n\\n[7]  R.  K.  Miller  and A.  N.  Michel,  Ordinary  Differential Equations, Academic Press, \\n\\n1982. \\n\\n[8]  I.  W.  Sandberg, Bell System  Tech.  J.  48, 35  (1969). \\n[9]  A.  N.  Michel,  IEEE  Trans.  on  Automatic  Control 28, 639  (1983). \\n[10]  A.  N.  Michel, J. A.  Farrell, and W.  Porod, submitted for  publication. \\n[11]  J.-H.  Li, A.  N.  Michel, and W.  Porod, IEEE  Trans.  Cire.  and Syst., in press. \\n[12]  G.  A.  Carpenter, M.  A.  Cohen,  and  S.  Grossberg,  Science  235,  1226  (1987). \\n[13]  M.  A.  Pai,  Power System  Stability, Amsterdam, North Holland,  1981. \\n[14]  A.  N.  Michel,  N.  R.  Sarabudla,  and  R.  K.  Miller,  Circuits,  Systems  and  Signal \\n\\nProcessing 1, 171  (1982). \\n\\n[15]  Lj.  T.  Grujic, A.  A.  Martynyuk and  M.  Ribbens-Pavella,  Stability  of Large-Scale \\nSystems  Under Structural and Singular Perturbations,  Nauka Dumka, Kiev,  1984. \\n\\n[16]  D.  K.  Ferry and W.  Porod,  Superlattices  and  Microstructures 2, 41  (1986). \\n\\n\\x0c'"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrT-55Qvqtiz"
      },
      "source": [
        "import spacy\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()\n",
        "\n",
        "gpe = [] # countries, cities, states\n",
        "\n",
        "city2 = []\n",
        "country2 = []\n",
        "\n",
        "for i in range(10):\n",
        "  gpe = []\n",
        "  doc = nlp(papers_df['full_text'][i].lower().split('abstract')[0].replace('\\n',''))\n",
        "  for ent in doc.ents:\n",
        "      if (ent.label_ == 'GPE'):\n",
        "          gpe.append(ent.text)\n",
        "  print('---------- Iteration Number ',i)\n",
        "  print(gpe)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5qQM7u44jLh"
      },
      "source": [
        "papers_df['full_text'][i].lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgG7dfCksQdS"
      },
      "source": [
        "i = 3\n",
        "papers_df['full_text'][i].lower().split('abstract')[0].replace('\\n','')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cE6uLVP5zHN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYzYo_Fm27eI"
      },
      "source": [
        "papers_df['full_text'][i].lower().split('abstract')[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM8dVlfa5StQ"
      },
      "source": [
        "papers_df['full_text'][i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZjze_JS5ZHf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
